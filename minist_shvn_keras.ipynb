{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# architecture 1 with SVHN dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAisAAAGHCAYAAABxmBIgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nVmkuVszMzKzS/h+4mPXSHUQQBwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f09e77d1710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73257 Images with 32 x 32 \n",
      "WARNING:tensorflow:From <ipython-input-8-c9cf1f4b3d4a>:176: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "Initialized\n",
      "Minibatch loss at step 0: 7.409079\n",
      "Minibatch accuracy: 6.2%\n",
      "Minibatch loss at step 50: 2.552974\n",
      "Minibatch accuracy: 6.2%\n",
      "Minibatch loss at step 100: 2.217019\n",
      "Minibatch accuracy: 12.5%\n",
      "Minibatch loss at step 150: 2.267467\n",
      "Minibatch accuracy: 12.5%\n",
      "Minibatch loss at step 200: 2.449726\n",
      "Minibatch accuracy: 6.2%\n",
      "Minibatch loss at step 250: 2.311006\n",
      "Minibatch accuracy: 6.2%\n",
      "Minibatch loss at step 300: 2.116477\n",
      "Minibatch accuracy: 25.0%\n",
      "Minibatch loss at step 350: 2.311157\n",
      "Minibatch accuracy: 25.0%\n",
      "Minibatch loss at step 400: 2.126116\n",
      "Minibatch accuracy: 25.0%\n",
      "Minibatch loss at step 450: 2.573571\n",
      "Minibatch accuracy: 12.5%\n",
      "Minibatch loss at step 500: 1.547323\n",
      "Minibatch accuracy: 50.0%\n",
      "Minibatch loss at step 550: 1.756100\n",
      "Minibatch accuracy: 50.0%\n",
      "Minibatch loss at step 600: 1.840487\n",
      "Minibatch accuracy: 37.5%\n",
      "Minibatch loss at step 650: 1.782119\n",
      "Minibatch accuracy: 37.5%\n",
      "Minibatch loss at step 700: 1.772927\n",
      "Minibatch accuracy: 37.5%\n",
      "Minibatch loss at step 750: 1.520782\n",
      "Minibatch accuracy: 37.5%\n",
      "Minibatch loss at step 800: 1.903188\n",
      "Minibatch accuracy: 56.2%\n",
      "Minibatch loss at step 850: 1.373178\n",
      "Minibatch accuracy: 50.0%\n",
      "Minibatch loss at step 900: 0.887687\n",
      "Minibatch accuracy: 75.0%\n",
      "Minibatch loss at step 950: 1.366125\n",
      "Minibatch accuracy: 68.8%\n",
      "Minibatch loss at step 1000: 1.011865\n",
      "Minibatch accuracy: 68.8%\n",
      "Minibatch loss at step 1050: 0.907941\n",
      "Minibatch accuracy: 75.0%\n",
      "Minibatch loss at step 1100: 1.346509\n",
      "Minibatch accuracy: 43.8%\n",
      "Minibatch loss at step 1150: 1.083056\n",
      "Minibatch accuracy: 56.2%\n",
      "Minibatch loss at step 1200: 0.980912\n",
      "Minibatch accuracy: 62.5%\n",
      "Minibatch loss at step 1250: 1.150718\n",
      "Minibatch accuracy: 75.0%\n",
      "Minibatch loss at step 1300: 0.794919\n",
      "Minibatch accuracy: 62.5%\n",
      "Minibatch loss at step 1350: 0.915721\n",
      "Minibatch accuracy: 75.0%\n",
      "Minibatch loss at step 1400: 1.755377\n",
      "Minibatch accuracy: 50.0%\n",
      "Minibatch loss at step 1450: 1.274127\n",
      "Minibatch accuracy: 56.2%\n",
      "Minibatch loss at step 1500: 1.015244\n",
      "Minibatch accuracy: 75.0%\n",
      "Minibatch loss at step 1550: 1.481037\n",
      "Minibatch accuracy: 56.2%\n",
      "Minibatch loss at step 1600: 1.582271\n",
      "Minibatch accuracy: 43.8%\n",
      "Minibatch loss at step 1650: 1.247463\n",
      "Minibatch accuracy: 50.0%\n",
      "Minibatch loss at step 1700: 1.476678\n",
      "Minibatch accuracy: 50.0%\n",
      "Minibatch loss at step 1750: 1.494329\n",
      "Minibatch accuracy: 75.0%\n",
      "Minibatch loss at step 1800: 1.715506\n",
      "Minibatch accuracy: 31.2%\n",
      "Minibatch loss at step 1850: 1.593430\n",
      "Minibatch accuracy: 43.8%\n",
      "Minibatch loss at step 1900: 1.276984\n",
      "Minibatch accuracy: 56.2%\n",
      "Minibatch loss at step 1950: 1.016124\n",
      "Minibatch accuracy: 56.2%\n",
      "Minibatch loss at step 2000: 1.503715\n",
      "Minibatch accuracy: 43.8%\n",
      "Minibatch loss at step 2050: 0.706994\n",
      "Minibatch accuracy: 75.0%\n",
      "Minibatch loss at step 2100: 0.400594\n",
      "Minibatch accuracy: 93.8%\n",
      "Minibatch loss at step 2150: 1.080338\n",
      "Minibatch accuracy: 62.5%\n",
      "Minibatch loss at step 2200: 1.161722\n",
      "Minibatch accuracy: 56.2%\n",
      "Minibatch loss at step 2250: 1.674218\n",
      "Minibatch accuracy: 62.5%\n",
      "Minibatch loss at step 2300: 0.449233\n",
      "Minibatch accuracy: 81.2%\n",
      "Minibatch loss at step 2350: 0.605723\n",
      "Minibatch accuracy: 81.2%\n",
      "Minibatch loss at step 2400: 0.780549\n",
      "Minibatch accuracy: 81.2%\n",
      "Minibatch loss at step 2450: 0.520359\n",
      "Minibatch accuracy: 81.2%\n",
      "Minibatch loss at step 2500: 0.552991\n",
      "Minibatch accuracy: 93.8%\n",
      "Minibatch loss at step 2550: 0.795206\n",
      "Minibatch accuracy: 75.0%\n",
      "Minibatch loss at step 2600: 0.987361\n",
      "Minibatch accuracy: 56.2%\n",
      "Minibatch loss at step 2650: 0.729975\n",
      "Minibatch accuracy: 75.0%\n",
      "Minibatch loss at step 2700: 1.098880\n",
      "Minibatch accuracy: 50.0%\n",
      "Minibatch loss at step 2750: 0.824956\n",
      "Minibatch accuracy: 75.0%\n",
      "Minibatch loss at step 2800: 0.618407\n",
      "Minibatch accuracy: 75.0%\n",
      "Minibatch loss at step 2850: 1.012647\n",
      "Minibatch accuracy: 68.8%\n",
      "Minibatch loss at step 2900: 0.533369\n",
      "Minibatch accuracy: 81.2%\n",
      "Minibatch loss at step 2950: 0.789114\n",
      "Minibatch accuracy: 87.5%\n",
      "Minibatch loss at step 3000: 1.092841\n",
      "Minibatch accuracy: 56.2%\n",
      "Minibatch loss at step 3050: 0.851350\n",
      "Minibatch accuracy: 81.2%\n",
      "Minibatch loss at step 3100: 0.917768\n",
      "Minibatch accuracy: 62.5%\n",
      "Minibatch loss at step 3150: 0.846416\n",
      "Minibatch accuracy: 68.8%\n",
      "Minibatch loss at step 3200: 0.365034\n",
      "Minibatch accuracy: 81.2%\n",
      "Minibatch loss at step 3250: 0.554489\n",
      "Minibatch accuracy: 81.2%\n",
      "Minibatch loss at step 3300: 1.219814\n",
      "Minibatch accuracy: 68.8%\n",
      "Minibatch loss at step 3350: 0.336642\n",
      "Minibatch accuracy: 87.5%\n",
      "Minibatch loss at step 3400: 0.572012\n",
      "Minibatch accuracy: 68.8%\n",
      "Minibatch loss at step 3450: 0.397513\n",
      "Minibatch accuracy: 75.0%\n",
      "Minibatch loss at step 3500: 0.507159\n",
      "Minibatch accuracy: 81.2%\n",
      "Minibatch loss at step 3550: 0.688163\n",
      "Minibatch accuracy: 81.2%\n",
      "Minibatch loss at step 3600: 1.202900\n",
      "Minibatch accuracy: 50.0%\n",
      "Minibatch loss at step 3650: 1.406066\n",
      "Minibatch accuracy: 62.5%\n",
      "Minibatch loss at step 3700: 0.914322\n",
      "Minibatch accuracy: 68.8%\n",
      "Minibatch loss at step 3750: 0.978352\n",
      "Minibatch accuracy: 62.5%\n",
      "Minibatch loss at step 3800: 0.821267\n",
      "Minibatch accuracy: 68.8%\n",
      "Minibatch loss at step 3850: 0.185753\n",
      "Minibatch accuracy: 93.8%\n",
      "Minibatch loss at step 3900: 0.182141\n",
      "Minibatch accuracy: 100.0%\n",
      "Minibatch loss at step 3950: 0.957918\n",
      "Minibatch accuracy: 68.8%\n",
      "Minibatch loss at step 4000: 2.112470\n",
      "Minibatch accuracy: 81.2%\n",
      "Minibatch loss at step 4050: 0.356358\n",
      "Minibatch accuracy: 87.5%\n",
      "Minibatch loss at step 4100: 0.541673\n",
      "Minibatch accuracy: 81.2%\n",
      "Minibatch loss at step 4150: 0.633700\n",
      "Minibatch accuracy: 81.2%\n",
      "Minibatch loss at step 4200: 1.000518\n",
      "Minibatch accuracy: 62.5%\n",
      "Minibatch loss at step 4250: 0.244087\n",
      "Minibatch accuracy: 87.5%\n",
      "Minibatch loss at step 4300: 0.873951\n",
      "Minibatch accuracy: 62.5%\n",
      "Minibatch loss at step 4350: 2.140422\n",
      "Minibatch accuracy: 50.0%\n",
      "Minibatch loss at step 4400: 0.507430\n",
      "Minibatch accuracy: 87.5%\n",
      "Minibatch loss at step 4450: 0.860064\n",
      "Minibatch accuracy: 75.0%\n",
      "Minibatch loss at step 4500: 1.010061\n",
      "Minibatch accuracy: 56.2%\n",
      "Minibatch loss at step 4550: 0.877654\n",
      "Minibatch accuracy: 75.0%\n",
      "Minibatch loss at step 4600: 0.488161\n",
      "Minibatch accuracy: 87.5%\n",
      "Minibatch loss at step 4650: 0.260469\n",
      "Minibatch accuracy: 100.0%\n",
      "Minibatch loss at step 4700: 0.424912\n",
      "Minibatch accuracy: 93.8%\n",
      "Minibatch loss at step 4750: 0.640698\n",
      "Minibatch accuracy: 81.2%\n",
      "Minibatch loss at step 4800: 1.065194\n",
      "Minibatch accuracy: 62.5%\n",
      "Minibatch loss at step 4850: 0.409624\n",
      "Minibatch accuracy: 87.5%\n",
      "Minibatch loss at step 4900: 0.847363\n",
      "Minibatch accuracy: 81.2%\n",
      "Minibatch loss at step 4950: 0.425381\n",
      "Minibatch accuracy: 87.5%\n",
      "Minibatch loss at step 5000: 0.578809\n",
      "Minibatch accuracy: 87.5%\n",
      "Minibatch loss at step 5050: 0.667803\n",
      "Minibatch accuracy: 81.2%\n",
      "Minibatch loss at step 5100: 0.672354\n",
      "Minibatch accuracy: 75.0%\n",
      "Minibatch loss at step 5150: 0.475916\n",
      "Minibatch accuracy: 81.2%\n",
      "Minibatch loss at step 5200: 0.372121\n",
      "Minibatch accuracy: 87.5%\n",
      "Minibatch loss at step 5250: 0.719659\n",
      "Minibatch accuracy: 81.2%\n",
      "Minibatch loss at step 5300: 1.694919\n",
      "Minibatch accuracy: 43.8%\n",
      "Minibatch loss at step 5350: 0.994681\n",
      "Minibatch accuracy: 68.8%\n",
      "Minibatch loss at step 5400: 0.838966\n",
      "Minibatch accuracy: 81.2%\n",
      "Minibatch loss at step 5450: 0.681507\n",
      "Minibatch accuracy: 75.0%\n",
      "Minibatch loss at step 5500: 0.527023\n",
      "Minibatch accuracy: 81.2%\n",
      "Minibatch loss at step 5550: 0.898375\n",
      "Minibatch accuracy: 81.2%\n",
      "Minibatch loss at step 5600: 1.626813\n",
      "Minibatch accuracy: 50.0%\n",
      "Minibatch loss at step 5650: 1.025701\n",
      "Minibatch accuracy: 62.5%\n",
      "Minibatch loss at step 5700: 0.502666\n",
      "Minibatch accuracy: 87.5%\n",
      "Minibatch loss at step 5750: 0.592761\n",
      "Minibatch accuracy: 81.2%\n",
      "Minibatch loss at step 5800: 0.575786\n",
      "Minibatch accuracy: 81.2%\n",
      "Minibatch loss at step 5850: 0.374604\n",
      "Minibatch accuracy: 93.8%\n",
      "Minibatch loss at step 5900: 1.180527\n",
      "Minibatch accuracy: 62.5%\n",
      "Minibatch loss at step 5950: 0.933996\n",
      "Minibatch accuracy: 62.5%\n",
      "Minibatch loss at step 6000: 1.090173\n",
      "Minibatch accuracy: 81.2%\n",
      "Minibatch loss at step 6050: 0.362397\n",
      "Minibatch accuracy: 93.8%\n",
      "Minibatch loss at step 6100: 1.422850\n",
      "Minibatch accuracy: 75.0%\n",
      "Minibatch loss at step 6150: 0.592654\n",
      "Minibatch accuracy: 81.2%\n",
      "Minibatch loss at step 6200: 0.823591\n",
      "Minibatch accuracy: 75.0%\n",
      "Minibatch loss at step 6250: 0.337954\n",
      "Minibatch accuracy: 81.2%\n",
      "Minibatch loss at step 6300: 0.749042\n",
      "Minibatch accuracy: 68.8%\n",
      "Minibatch loss at step 6350: 0.878930\n",
      "Minibatch accuracy: 81.2%\n",
      "Minibatch loss at step 6400: 0.971357\n",
      "Minibatch accuracy: 68.8%\n",
      "Minibatch loss at step 6450: 1.084940\n",
      "Minibatch accuracy: 75.0%\n",
      "Minibatch loss at step 6500: 0.511898\n",
      "Minibatch accuracy: 75.0%\n",
      "Minibatch loss at step 6550: 0.510617\n",
      "Minibatch accuracy: 81.2%\n",
      "Minibatch loss at step 6600: 0.455514\n",
      "Minibatch accuracy: 75.0%\n",
      "Minibatch loss at step 6650: 1.653717\n",
      "Minibatch accuracy: 68.8%\n",
      "Minibatch loss at step 6700: 1.013543\n",
      "Minibatch accuracy: 68.8%\n",
      "Minibatch loss at step 6750: 0.623262\n",
      "Minibatch accuracy: 87.5%\n",
      "Minibatch loss at step 6800: 0.387869\n",
      "Minibatch accuracy: 93.8%\n",
      "Minibatch loss at step 6850: 1.355836\n",
      "Minibatch accuracy: 62.5%\n",
      "Minibatch loss at step 6900: 0.850899\n",
      "Minibatch accuracy: 81.2%\n",
      "Minibatch loss at step 6950: 0.789998\n",
      "Minibatch accuracy: 68.8%\n",
      "Minibatch loss at step 7000: 0.862096\n",
      "Minibatch accuracy: 75.0%\n",
      "Minibatch loss at step 7050: 1.217520\n",
      "Minibatch accuracy: 62.5%\n",
      "Minibatch loss at step 7100: 0.605968\n",
      "Minibatch accuracy: 87.5%\n",
      "Minibatch loss at step 7150: 0.689225\n",
      "Minibatch accuracy: 75.0%\n",
      "Minibatch loss at step 7200: 0.621511\n",
      "Minibatch accuracy: 81.2%\n",
      "Minibatch loss at step 7250: 0.470277\n",
      "Minibatch accuracy: 81.2%\n",
      "Minibatch loss at step 7300: 0.978312\n",
      "Minibatch accuracy: 81.2%\n",
      "Minibatch loss at step 7350: 0.562152\n",
      "Minibatch accuracy: 87.5%\n",
      "Minibatch loss at step 7400: 0.272070\n",
      "Minibatch accuracy: 93.8%\n",
      "Minibatch loss at step 7450: 0.555117\n",
      "Minibatch accuracy: 93.8%\n",
      "Minibatch loss at step 7500: 0.250901\n",
      "Minibatch accuracy: 93.8%\n",
      "Minibatch loss at step 7550: 0.564534\n",
      "Minibatch accuracy: 75.0%\n",
      "Minibatch loss at step 7600: 0.415968\n",
      "Minibatch accuracy: 93.8%\n",
      "Minibatch loss at step 7650: 0.904528\n",
      "Minibatch accuracy: 68.8%\n",
      "Minibatch loss at step 7700: 0.325493\n",
      "Minibatch accuracy: 93.8%\n",
      "Minibatch loss at step 7750: 0.563455\n",
      "Minibatch accuracy: 75.0%\n",
      "Minibatch loss at step 7800: 0.196128\n",
      "Minibatch accuracy: 93.8%\n",
      "Minibatch loss at step 7850: 0.391692\n",
      "Minibatch accuracy: 87.5%\n",
      "Minibatch loss at step 7900: 0.893952\n",
      "Minibatch accuracy: 81.2%\n",
      "Minibatch loss at step 7950: 0.503039\n",
      "Minibatch accuracy: 93.8%\n",
      "Minibatch loss at step 8000: 0.821803\n",
      "Minibatch accuracy: 68.8%\n",
      "Minibatch loss at step 8050: 0.562192\n",
      "Minibatch accuracy: 81.2%\n",
      "Minibatch loss at step 8100: 0.435167\n",
      "Minibatch accuracy: 87.5%\n",
      "Minibatch loss at step 8150: 0.910304\n",
      "Minibatch accuracy: 75.0%\n",
      "Minibatch loss at step 8200: 0.589127\n",
      "Minibatch accuracy: 81.2%\n",
      "Minibatch loss at step 8250: 0.805106\n",
      "Minibatch accuracy: 62.5%\n",
      "Minibatch loss at step 8300: 0.446846\n",
      "Minibatch accuracy: 87.5%\n",
      "Minibatch loss at step 8350: 0.286749\n",
      "Minibatch accuracy: 93.8%\n",
      "Minibatch loss at step 8400: 0.417028\n",
      "Minibatch accuracy: 81.2%\n",
      "Minibatch loss at step 8450: 0.165700\n",
      "Minibatch accuracy: 93.8%\n",
      "Minibatch loss at step 8500: 0.259915\n",
      "Minibatch accuracy: 87.5%\n",
      "Minibatch loss at step 8550: 0.311771\n",
      "Minibatch accuracy: 87.5%\n",
      "Minibatch loss at step 8600: 0.741706\n",
      "Minibatch accuracy: 75.0%\n",
      "Minibatch loss at step 8650: 0.198246\n",
      "Minibatch accuracy: 100.0%\n",
      "Minibatch loss at step 8700: 1.088835\n",
      "Minibatch accuracy: 68.8%\n",
      "Minibatch loss at step 8750: 0.225929\n",
      "Minibatch accuracy: 100.0%\n",
      "Minibatch loss at step 8800: 0.648991\n",
      "Minibatch accuracy: 75.0%\n",
      "Minibatch loss at step 8850: 0.550626\n",
      "Minibatch accuracy: 87.5%\n",
      "Minibatch loss at step 8900: 0.570502\n",
      "Minibatch accuracy: 81.2%\n",
      "Minibatch loss at step 8950: 0.531343\n",
      "Minibatch accuracy: 75.0%\n",
      "Minibatch loss at step 9000: 0.363291\n",
      "Minibatch accuracy: 100.0%\n",
      "Minibatch loss at step 9050: 0.305220\n",
      "Minibatch accuracy: 93.8%\n",
      "Minibatch loss at step 9100: 0.765587\n",
      "Minibatch accuracy: 68.8%\n",
      "Minibatch loss at step 9150: 1.363413\n",
      "Minibatch accuracy: 56.2%\n",
      "Minibatch loss at step 9200: 0.874022\n",
      "Minibatch accuracy: 68.8%\n",
      "Minibatch loss at step 9250: 0.895912\n",
      "Minibatch accuracy: 68.8%\n",
      "Minibatch loss at step 9300: 0.720041\n",
      "Minibatch accuracy: 81.2%\n",
      "Minibatch loss at step 9350: 1.038406\n",
      "Minibatch accuracy: 81.2%\n",
      "Minibatch loss at step 9400: 0.545263\n",
      "Minibatch accuracy: 81.2%\n",
      "Minibatch loss at step 9450: 0.561313\n",
      "Minibatch accuracy: 87.5%\n",
      "Minibatch loss at step 9500: 0.290718\n",
      "Minibatch accuracy: 87.5%\n",
      "Minibatch loss at step 9550: 0.519926\n",
      "Minibatch accuracy: 87.5%\n",
      "Minibatch loss at step 9600: 0.151894\n",
      "Minibatch accuracy: 93.8%\n",
      "Minibatch loss at step 9650: 1.273656\n",
      "Minibatch accuracy: 68.8%\n",
      "Minibatch loss at step 9700: 0.228268\n",
      "Minibatch accuracy: 93.8%\n",
      "Minibatch loss at step 9750: 0.480387\n",
      "Minibatch accuracy: 87.5%\n",
      "Minibatch loss at step 9800: 0.972191\n",
      "Minibatch accuracy: 68.8%\n",
      "Minibatch loss at step 9850: 0.754169\n",
      "Minibatch accuracy: 75.0%\n",
      "Minibatch loss at step 9900: 0.053884\n",
      "Minibatch accuracy: 100.0%\n",
      "Minibatch loss at step 9950: 0.705617\n",
      "Minibatch accuracy: 81.2%\n",
      "Average Accuracy : 71.039375 \n",
      "END OF TRAINING\n",
      "0.785111\n",
      "END OF TESTING\n"
     ]
    }
   ],
   "source": [
    "# source: https://github.com/arpitgogia/ImageRecognition/blob/master/main.py\n",
    "# accuracy: 88%\n",
    "import tensorflow as tf \n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "#==================EXTRACTING AND ANALYSING DATA FROM .mat FILES===============\n",
    "\"\"\"\n",
    "X and Y Components of Training and Testing Data\n",
    "\"\"\"\n",
    "train_data = scipy.io.loadmat('data/svhn_cropped/train_32x32.mat')['X']\n",
    "train_labels = scipy.io.loadmat('data/svhn_cropped/train_32x32.mat')['y']\n",
    "test_data = scipy.io.loadmat('data/svhn_cropped/test_32x32.mat')['X']\n",
    "test_labels = scipy.io.loadmat('data/svhn_cropped/test_32x32.mat')['y']\n",
    "shape_train = train_data.shape\n",
    "shape_test = test_data.shape\n",
    "\"\"\"\n",
    "Plotting Class Labels against their respective frequencies in a Bar Graph\n",
    "\"\"\"\n",
    "temp_labels = train_labels.reshape(73257).tolist()\n",
    "temp_labels = dict(Counter(temp_labels))\n",
    "plt.bar(range(len(temp_labels)), temp_labels.values(), align='center', label='Training Labels')\n",
    "plt.xticks(range(len(temp_labels)), temp_labels.keys())\n",
    "temp_labels = test_labels.reshape(26032).tolist()\n",
    "temp_labels = dict(Counter(temp_labels))\n",
    "plt.bar(range(len(temp_labels)), temp_labels.values(), align='center', color='red', label='Testing Labels')\n",
    "plt.legend()\n",
    "plt.xlabel('Class Labels')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Frequency Distribution of Class Labels')\n",
    "plt.show()\n",
    "#============================================================================\n",
    "\n",
    "\n",
    "# print shape_train[3], \"Images with\", shape_train[0], \"x\", shape_train[0], \"RGB grid\"\n",
    "print(\"%d Images with %d x %d \" % (shape_train[3], shape_train[0], shape_train[0]))\n",
    "\n",
    "#==================NORMALISATION AND PREPROCESSING=============================================\n",
    "\n",
    "train_data = train_data.astype('float32') / 128.0 - 1\n",
    "test_data = test_data.astype('float32') / 128.0 - 1\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Converting Labels to One Hot Encoding and Image Matrix to favourable dimensions\n",
    "\"\"\"\n",
    "def reformat(data, Y):\n",
    "    xtrain = []\n",
    "    trainLen = data.shape[3]\n",
    "    for x in range(trainLen):\n",
    "        xtrain.append(data[:,:,:,x])\n",
    "    xtrain = np.asarray(xtrain)\n",
    "    Ytr=[]\n",
    "    for el in Y:\n",
    "        temp=np.zeros(10)\n",
    "        if el==10:\n",
    "            temp[0]=1\n",
    "        elif el==1:\n",
    "            temp[1]=1\n",
    "        elif el==2:\n",
    "            temp[2]=1\n",
    "        elif el==3:\n",
    "            temp[3]=1\n",
    "        elif el==4:\n",
    "            temp[4]=1\n",
    "        elif el==5:\n",
    "            temp[5]=1\n",
    "        elif el==6:\n",
    "            temp[6]=1\n",
    "        elif el==7:\n",
    "            temp[7]=1\n",
    "        elif el==8:\n",
    "            temp[8]=1\n",
    "        elif el==9:\n",
    "            temp[9]=1\n",
    "        Ytr.append(temp)\n",
    "    return xtrain, np.asarray(Ytr)\n",
    "\n",
    "train_data, train_labels = reformat(train_data, train_labels)\n",
    "test_data, test_labels = reformat(test_data, test_labels)\n",
    "\n",
    "\n",
    "#============================================================================\n",
    "\n",
    "#==================BUILDING THE CNN==========================================\n",
    "\"\"\"\n",
    "Various Hyperparameters required for training the CNN.\n",
    "\"\"\"\n",
    "image_size = 32\n",
    "width = 32\n",
    "height = 32\n",
    "channels = 3\n",
    "\n",
    "n_labels = 10\n",
    "patch = 5\n",
    "depth = 16\n",
    "hidden = 128\n",
    "dropout = 0.9375\n",
    "\n",
    "batch = 16\n",
    "learning_rate = 0.001\n",
    "\n",
    "\"\"\"\n",
    "Constructing the placeholders and variables in the TensorFlow Graph\n",
    "\"\"\"\n",
    "# Training Dataset\n",
    "tf_train_dataset = tf.placeholder(tf.float32, shape=(None, width, height, channels))\n",
    "# Training Labels\n",
    "tf_train_labels = tf.placeholder(tf.float32, shape=(None, n_labels))\n",
    "# Testing Dataset\n",
    "tf_test_dataset = tf.constant(test_data)\n",
    "\n",
    "#   Layer 1: (5, 5, 3, 16)\n",
    "layer1_weights = tf.Variable(tf.truncated_normal([patch, patch, channels, depth], stddev=0.1))\n",
    "layer1_biases = tf.Variable(tf.constant(1.0, shape=[depth]))\n",
    "\n",
    "#   Layer 2: (5, 5, 16, 16)\n",
    "layer2_weights = tf.Variable(tf.truncated_normal([patch, patch, depth, depth], stddev=0.1))\n",
    "layer2_biases = tf.Variable(tf.constant(1.0, shape=[depth]))\n",
    "\n",
    "#   Layer 3: (1024, 128)\n",
    "layer3_weights = tf.Variable(tf.truncated_normal([image_size // 4 * image_size // 4 * depth, hidden], stddev=0.1))\n",
    "layer3_biases = tf.Variable(tf.constant(1.0, shape=[hidden]))\n",
    "\n",
    "#   Layer 4: (128, 10)\n",
    "layer4_weights = tf.Variable(tf.truncated_normal([hidden, n_labels], stddev=0.1))\n",
    "layer4_biases = tf.Variable(tf.constant(1.0, shape=[n_labels]))\n",
    "\n",
    "dropout = tf.placeholder(tf.float32)\n",
    "\n",
    "def model(data):\n",
    "    #   Convolution 1 and RELU\n",
    "    conv1 = tf.nn.conv2d(data, layer1_weights, [1, 1, 1, 1], padding='SAME')\n",
    "    hidden1 = tf.nn.relu(conv1 + layer1_biases)\n",
    "    #   Max Pool\n",
    "    hidden2 = tf.nn.max_pool(hidden1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "    #   Convolution 2 and RELU\n",
    "    conv2 = tf.nn.conv2d(hidden2, layer2_weights, [1, 1, 1, 1], padding='SAME')\n",
    "    hidden3 = tf.nn.relu(conv2 + layer2_biases)\n",
    "    #   Max Pool\n",
    "    hidden4 = tf.nn.max_pool(hidden3, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "    shape = hidden4.get_shape().as_list()\n",
    "\n",
    "    reshape = tf.reshape(hidden4, [-1, shape[1] * shape[2] * shape[3]])\n",
    "    hidden5 = tf.nn.relu(tf.matmul(reshape, layer3_weights) + layer3_biases)\n",
    "    #   Dropout\n",
    "    dropout_layer = tf.nn.dropout(hidden5, 0.93)\n",
    "    \n",
    "    return tf.matmul(dropout_layer, layer4_weights) + layer4_biases\n",
    "\n",
    "logits = model(tf_train_dataset)\n",
    "# bug here \n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=tf_train_labels))\n",
    "optimizer = tf.train.AdamOptimizer(0.001).minimize(loss)\n",
    "\n",
    "train_prediction = tf.nn.softmax(logits)\n",
    "test_prediction = tf.nn.softmax(model(tf_test_dataset))\n",
    "#============================================================================\n",
    "\n",
    "#==================TRAINING AND TESTING THE MODEL============================\n",
    "\"\"\"\n",
    "Accuracy function defined similar to the one taught in the Udacity Deep Learning Course\n",
    "Returns percentage of correct predictions by verifying with Labels\n",
    "\"\"\"\n",
    "def accuracy(predictions, labels):\n",
    "    return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "          / predictions.shape[0])\n",
    "\n",
    "#   Number of iterations\n",
    "num_steps = 10000\n",
    "\n",
    "with tf.Session() as session:\n",
    "    tf.initialize_all_variables().run()\n",
    "    print('Initialized')\n",
    "    average = 0\n",
    "    for step in range(num_steps):\n",
    "        #   Constucting the batch from the data set\n",
    "        offset = (step * batch) % (train_labels.shape[0] - batch)\n",
    "        batch_data = train_data[offset:(offset + batch), :, :, :]\n",
    "        batch_labels = train_labels[offset:(offset + batch), :]\n",
    "        #   Dictionary to be fed to TensorFlow Session\n",
    "        feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels, dropout: 0.93}\n",
    "        _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "        #   Calculating the Accuracy of the predictions\n",
    "        accu = accuracy(predictions, batch_labels)\n",
    "        if (step % 50 == 0):\n",
    "            print('Minibatch loss at step %d: %f' % (step, l))\n",
    "            print('Minibatch accuracy: %.1f%%' % accu)\n",
    "        average += accu\n",
    "    print(\"Average Accuracy : %f \" % (average / num_steps))\n",
    "    print(\"END OF TRAINING\")\n",
    "\n",
    "      # Test trained model\n",
    "    correct_prediction = tf.equal(tf.argmax(test_prediction, 1), tf.argmax(test_labels, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    print(session.run(accuracy))\n",
    "    print(\"END OF TESTING\")\n",
    "#    average = 0\n",
    "#     for step in range(num_steps):\n",
    "#         #   Constucting the batch from the data set\n",
    "#         offset = (step * batch) % (test_labels.shape[0] - batch)\n",
    "#         batch_data = test_data[offset:(offset + batch), :, :, :]\n",
    "#         batch_labels = test_labels[offset:(offset + batch), :]\n",
    "#         #   Dictionary to be fed to TensorFlow Session\n",
    "#         feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels, dropout: 0.93}\n",
    "#         _, l, predictions = session.run([optimizer, loss, test_prediction], feed_dict=feed_dict)\n",
    "#         #   Calculating the Accuracy of the predictions\n",
    "#         accu = accuracy(predictions, batch_labels)\n",
    "#         if (step % 50 == 0):\n",
    "#             print('Minibatch loss at step %d: %f' % (step, l))\n",
    "#             print('Minibatch accuracy: %.1f%%' % accu)\n",
    "#         average += accu\n",
    "#     print(\"Average Accuracy : %f \" % (average / num_steps))\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# use the same model architecture to train on MNIST: result isn't good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "(55000, 784)\n",
      "(10000, 784)\n",
      "(55000, 10)\n",
      "after reshape: \n",
      "(55000, 28, 28, 1)\n",
      "(10000, 28, 28, 1)\n",
      "WARNING:tensorflow:From <ipython-input-9-d7a1af342326>:194: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "Initialized\n",
      "Minibatch loss at step 0: 11.371773\n",
      "Minibatch accuracy: 10.2%\n",
      "Minibatch loss at step 50: 3.096071\n",
      "Minibatch accuracy: 14.1%\n",
      "Minibatch loss at step 100: 2.419096\n",
      "Minibatch accuracy: 7.8%\n",
      "Minibatch loss at step 150: 2.306524\n",
      "Minibatch accuracy: 11.7%\n",
      "Minibatch loss at step 200: 2.313264\n",
      "Minibatch accuracy: 5.5%\n",
      "Minibatch loss at step 250: 2.300894\n",
      "Minibatch accuracy: 12.5%\n",
      "Minibatch loss at step 300: 2.302557\n",
      "Minibatch accuracy: 9.4%\n",
      "Minibatch loss at step 350: 2.302116\n",
      "Minibatch accuracy: 13.3%\n",
      "Minibatch loss at step 400: 2.302770\n",
      "Minibatch accuracy: 9.4%\n",
      "Minibatch loss at step 450: 2.301948\n",
      "Minibatch accuracy: 14.1%\n",
      "Minibatch loss at step 500: 2.302912\n",
      "Minibatch accuracy: 10.2%\n",
      "Minibatch loss at step 550: 2.302695\n",
      "Minibatch accuracy: 7.8%\n",
      "Minibatch loss at step 600: 2.301766\n",
      "Minibatch accuracy: 15.6%\n",
      "Minibatch loss at step 650: 2.300475\n",
      "Minibatch accuracy: 18.0%\n",
      "Minibatch loss at step 700: 2.301351\n",
      "Minibatch accuracy: 12.5%\n",
      "Minibatch loss at step 750: 2.300716\n",
      "Minibatch accuracy: 14.8%\n",
      "Minibatch loss at step 800: 2.301117\n",
      "Minibatch accuracy: 13.3%\n",
      "Minibatch loss at step 850: 2.301917\n",
      "Minibatch accuracy: 11.7%\n",
      "Minibatch loss at step 900: 2.302148\n",
      "Minibatch accuracy: 11.7%\n",
      "Minibatch loss at step 950: 2.301032\n",
      "Minibatch accuracy: 15.6%\n",
      "Minibatch loss at step 1000: 2.301329\n",
      "Minibatch accuracy: 11.7%\n",
      "Minibatch loss at step 1050: 2.303954\n",
      "Minibatch accuracy: 8.6%\n",
      "Minibatch loss at step 1100: 2.301463\n",
      "Minibatch accuracy: 10.9%\n",
      "Minibatch loss at step 1150: 2.301608\n",
      "Minibatch accuracy: 12.5%\n",
      "Minibatch loss at step 1200: 2.301255\n",
      "Minibatch accuracy: 11.7%\n",
      "Minibatch loss at step 1250: 2.301964\n",
      "Minibatch accuracy: 11.7%\n",
      "Minibatch loss at step 1300: 2.302924\n",
      "Minibatch accuracy: 9.4%\n",
      "Minibatch loss at step 1350: 2.302315\n",
      "Minibatch accuracy: 10.2%\n",
      "Minibatch loss at step 1400: 2.302346\n",
      "Minibatch accuracy: 11.7%\n",
      "Minibatch loss at step 1450: 2.302979\n",
      "Minibatch accuracy: 9.4%\n",
      "Minibatch loss at step 1500: 2.301766\n",
      "Minibatch accuracy: 12.5%\n",
      "Minibatch loss at step 1550: 2.303329\n",
      "Minibatch accuracy: 10.9%\n",
      "Minibatch loss at step 1600: 2.302164\n",
      "Minibatch accuracy: 12.5%\n",
      "Minibatch loss at step 1650: 2.304101\n",
      "Minibatch accuracy: 7.0%\n",
      "Minibatch loss at step 1700: 2.300275\n",
      "Minibatch accuracy: 10.2%\n",
      "Minibatch loss at step 1750: 2.300662\n",
      "Minibatch accuracy: 12.5%\n",
      "Minibatch loss at step 1800: 2.300330\n",
      "Minibatch accuracy: 12.5%\n",
      "Minibatch loss at step 1850: 2.301649\n",
      "Minibatch accuracy: 10.2%\n",
      "Minibatch loss at step 1900: 2.297875\n",
      "Minibatch accuracy: 14.8%\n",
      "Minibatch loss at step 1950: 2.305339\n",
      "Minibatch accuracy: 6.2%\n",
      "Minibatch loss at step 2000: 2.298885\n",
      "Minibatch accuracy: 14.8%\n",
      "Minibatch loss at step 2050: 2.303200\n",
      "Minibatch accuracy: 12.5%\n",
      "Minibatch loss at step 2100: 2.300766\n",
      "Minibatch accuracy: 11.7%\n",
      "Minibatch loss at step 2150: 2.300404\n",
      "Minibatch accuracy: 13.3%\n",
      "Minibatch loss at step 2200: 2.301103\n",
      "Minibatch accuracy: 8.6%\n",
      "Minibatch loss at step 2250: 2.299315\n",
      "Minibatch accuracy: 12.5%\n",
      "Minibatch loss at step 2300: 2.297389\n",
      "Minibatch accuracy: 14.1%\n",
      "Minibatch loss at step 2350: 2.302784\n",
      "Minibatch accuracy: 9.4%\n",
      "Minibatch loss at step 2400: 2.297891\n",
      "Minibatch accuracy: 13.3%\n",
      "Minibatch loss at step 2450: 2.301117\n",
      "Minibatch accuracy: 11.7%\n",
      "Minibatch loss at step 2500: 2.302687\n",
      "Minibatch accuracy: 8.6%\n",
      "Minibatch loss at step 2550: 2.304829\n",
      "Minibatch accuracy: 7.8%\n",
      "Minibatch loss at step 2600: 2.299625\n",
      "Minibatch accuracy: 14.1%\n",
      "Minibatch loss at step 2650: 2.300348\n",
      "Minibatch accuracy: 13.3%\n",
      "Minibatch loss at step 2700: 2.298763\n",
      "Minibatch accuracy: 14.1%\n",
      "Minibatch loss at step 2750: 2.297906\n",
      "Minibatch accuracy: 13.3%\n",
      "Minibatch loss at step 2800: 2.297276\n",
      "Minibatch accuracy: 12.5%\n",
      "Minibatch loss at step 2850: 2.301350\n",
      "Minibatch accuracy: 11.7%\n",
      "Minibatch loss at step 2900: 2.306825\n",
      "Minibatch accuracy: 8.6%\n",
      "Minibatch loss at step 2950: 2.300076\n",
      "Minibatch accuracy: 12.5%\n",
      "Minibatch loss at step 3000: 2.299348\n",
      "Minibatch accuracy: 12.5%\n",
      "Minibatch loss at step 3050: 2.301612\n",
      "Minibatch accuracy: 14.1%\n",
      "Minibatch loss at step 3100: 2.299340\n",
      "Minibatch accuracy: 10.9%\n",
      "Minibatch loss at step 3150: 2.299641\n",
      "Minibatch accuracy: 13.3%\n",
      "Minibatch loss at step 3200: 2.300653\n",
      "Minibatch accuracy: 12.5%\n",
      "Minibatch loss at step 3250: 2.298889\n",
      "Minibatch accuracy: 14.8%\n",
      "Minibatch loss at step 3300: 2.298747\n",
      "Minibatch accuracy: 12.5%\n",
      "Minibatch loss at step 3350: 2.303018\n",
      "Minibatch accuracy: 9.4%\n",
      "Minibatch loss at step 3400: 2.304018\n",
      "Minibatch accuracy: 9.4%\n",
      "Minibatch loss at step 3450: 2.297808\n",
      "Minibatch accuracy: 14.1%\n",
      "Minibatch loss at step 3500: 2.303311\n",
      "Minibatch accuracy: 10.2%\n",
      "Minibatch loss at step 3550: 2.302567\n",
      "Minibatch accuracy: 8.6%\n",
      "Minibatch loss at step 3600: 2.302463\n",
      "Minibatch accuracy: 10.2%\n",
      "Minibatch loss at step 3650: 2.301638\n",
      "Minibatch accuracy: 11.7%\n",
      "Minibatch loss at step 3700: 2.304387\n",
      "Minibatch accuracy: 9.4%\n",
      "Minibatch loss at step 3750: 2.296432\n",
      "Minibatch accuracy: 11.7%\n",
      "Minibatch loss at step 3800: 2.302080\n",
      "Minibatch accuracy: 10.2%\n",
      "Minibatch loss at step 3850: 2.303997\n",
      "Minibatch accuracy: 10.2%\n",
      "Minibatch loss at step 3900: 2.301807\n",
      "Minibatch accuracy: 11.7%\n",
      "Minibatch loss at step 3950: 2.302713\n",
      "Minibatch accuracy: 8.6%\n",
      "Minibatch loss at step 4000: 2.302186\n",
      "Minibatch accuracy: 11.7%\n",
      "Minibatch loss at step 4050: 2.298831\n",
      "Minibatch accuracy: 13.3%\n",
      "Minibatch loss at step 4100: 2.304491\n",
      "Minibatch accuracy: 7.0%\n",
      "Minibatch loss at step 4150: 2.301407\n",
      "Minibatch accuracy: 10.9%\n",
      "Minibatch loss at step 4200: 2.305402\n",
      "Minibatch accuracy: 9.4%\n",
      "Minibatch loss at step 4250: 2.303845\n",
      "Minibatch accuracy: 10.2%\n",
      "Minibatch loss at step 4300: 2.301086\n",
      "Minibatch accuracy: 11.7%\n",
      "Minibatch loss at step 4350: 2.293963\n",
      "Minibatch accuracy: 12.5%\n",
      "Minibatch loss at step 4400: 2.304785\n",
      "Minibatch accuracy: 9.4%\n",
      "Minibatch loss at step 4450: 2.299692\n",
      "Minibatch accuracy: 12.5%\n",
      "Minibatch loss at step 4500: 2.302829\n",
      "Minibatch accuracy: 12.5%\n",
      "Minibatch loss at step 4550: 2.296919\n",
      "Minibatch accuracy: 15.6%\n",
      "Minibatch loss at step 4600: 2.303825\n",
      "Minibatch accuracy: 9.4%\n",
      "Minibatch loss at step 4650: 2.299828\n",
      "Minibatch accuracy: 12.5%\n",
      "Minibatch loss at step 4700: 2.298473\n",
      "Minibatch accuracy: 11.7%\n",
      "Minibatch loss at step 4750: 2.299368\n",
      "Minibatch accuracy: 8.6%\n",
      "Minibatch loss at step 4800: 2.301545\n",
      "Minibatch accuracy: 11.7%\n",
      "Minibatch loss at step 4850: 2.304960\n",
      "Minibatch accuracy: 7.8%\n",
      "Minibatch loss at step 4900: 2.302279\n",
      "Minibatch accuracy: 10.2%\n",
      "Minibatch loss at step 4950: 2.306312\n",
      "Minibatch accuracy: 7.8%\n",
      "Minibatch loss at step 5000: 2.298533\n",
      "Minibatch accuracy: 13.3%\n",
      "Minibatch loss at step 5050: 2.303678\n",
      "Minibatch accuracy: 10.9%\n",
      "Minibatch loss at step 5100: 2.304008\n",
      "Minibatch accuracy: 8.6%\n",
      "Minibatch loss at step 5150: 2.299151\n",
      "Minibatch accuracy: 11.7%\n",
      "Minibatch loss at step 5200: 2.295379\n",
      "Minibatch accuracy: 13.3%\n",
      "Minibatch loss at step 5250: 2.302361\n",
      "Minibatch accuracy: 10.2%\n",
      "Minibatch loss at step 5300: 2.296410\n",
      "Minibatch accuracy: 12.5%\n",
      "Minibatch loss at step 5350: 2.300551\n",
      "Minibatch accuracy: 11.7%\n",
      "Minibatch loss at step 5400: 2.304266\n",
      "Minibatch accuracy: 9.4%\n",
      "Minibatch loss at step 5450: 2.299929\n",
      "Minibatch accuracy: 9.4%\n",
      "Minibatch loss at step 5500: 2.304423\n",
      "Minibatch accuracy: 13.3%\n",
      "Minibatch loss at step 5550: 2.303277\n",
      "Minibatch accuracy: 13.3%\n",
      "Minibatch loss at step 5600: 2.295180\n",
      "Minibatch accuracy: 14.1%\n",
      "Minibatch loss at step 5650: 2.299613\n",
      "Minibatch accuracy: 14.8%\n",
      "Minibatch loss at step 5700: 2.302321\n",
      "Minibatch accuracy: 10.9%\n",
      "Minibatch loss at step 5750: 2.299055\n",
      "Minibatch accuracy: 11.7%\n",
      "Minibatch loss at step 5800: 2.297220\n",
      "Minibatch accuracy: 12.5%\n",
      "Minibatch loss at step 5850: 2.301734\n",
      "Minibatch accuracy: 9.4%\n",
      "Minibatch loss at step 5900: 2.301732\n",
      "Minibatch accuracy: 10.9%\n",
      "Minibatch loss at step 5950: 2.300069\n",
      "Minibatch accuracy: 12.5%\n",
      "Minibatch loss at step 6000: 2.298019\n",
      "Minibatch accuracy: 12.5%\n",
      "Minibatch loss at step 6050: 2.292364\n",
      "Minibatch accuracy: 16.4%\n",
      "Minibatch loss at step 6100: 2.297085\n",
      "Minibatch accuracy: 14.1%\n",
      "Minibatch loss at step 6150: 2.307895\n",
      "Minibatch accuracy: 8.6%\n",
      "Minibatch loss at step 6200: 2.301876\n",
      "Minibatch accuracy: 10.9%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-d7a1af342326>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;31m#   Dictionary to be fed to TensorFlow Session\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mtf_train_dataset\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mbatch_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf_train_labels\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.93\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_prediction\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0;31m#   Calculating the Accuracy of the predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0maccu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/assistant/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/assistant/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/assistant/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/assistant/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/assistant/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# source: https://github.com/arpitgogia/ImageRecognition/blob/master/main.py\n",
    "# accuracy: 88%\n",
    "import tensorflow as tf \n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "train_data = mnist.train.images\n",
    "train_labels = mnist.train.labels\n",
    "test_data = mnist.test.images\n",
    "test_labels = mnist.test.labels\n",
    "shape_train = train_data.shape\n",
    "shape_test = test_data.shape\n",
    "print(shape_train)\n",
    "print(shape_test)\n",
    "print(train_labels.shape)\n",
    "print(\"after reshape: \")\n",
    "train_data = train_data.reshape(len(train_data), 28, 28, 1)\n",
    "test_data = test_data.reshape(len(test_data), 28, 28, 1)\n",
    "shape_train = train_data.shape\n",
    "shape_test = test_data.shape\n",
    "print(shape_train)\n",
    "print(shape_test)\n",
    "# \"\"\"\n",
    "# Plotting Class Labels against their respective frequencies in a Bar Graph\n",
    "# \"\"\"\n",
    "# temp_labels = train_labels.reshape(73257).tolist()\n",
    "# temp_labels = dict(Counter(temp_labels))\n",
    "# plt.bar(range(len(temp_labels)), temp_labels.values(), align='center', label='Training Labels')\n",
    "# plt.xticks(range(len(temp_labels)), temp_labels.keys())\n",
    "# temp_labels = test_labels.reshape(26032).tolist()\n",
    "# temp_labels = dict(Counter(temp_labels))\n",
    "# plt.bar(range(len(temp_labels)), temp_labels.values(), align='center', color='red', label='Testing Labels')\n",
    "# plt.legend()\n",
    "# plt.xlabel('Class Labels')\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.title('Frequency Distribution of Class Labels')\n",
    "# plt.show()\n",
    "#============================================================================\n",
    "\n",
    "\n",
    "# print shape_train[3], \"Images with\", shape_train[0], \"x\", shape_train[0], \"RGB grid\"\n",
    "# print(\"%d Images with %d x %d \" % (shape_train[3], shape_train[0], shape_train[0]))\n",
    "\n",
    "#==================NORMALISATION AND PREPROCESSING=============================================\n",
    "# do I need to do normalization here? why - 1?\n",
    "train_data = train_data.astype('float32') / 128.0 - 1\n",
    "test_data = test_data.astype('float32') / 128.0 - 1\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Converting Labels to One Hot Encoding and Image Matrix to favourable dimensions\n",
    "\"\"\"\n",
    "def reformat(data, Y):\n",
    "    xtrain = []\n",
    "    trainLen = data.shape[3]\n",
    "    for x in range(trainLen):\n",
    "        xtrain.append(data[:,:,:,x])\n",
    "    xtrain = np.asarray(xtrain)\n",
    "    Ytr=[]\n",
    "    for el in Y:\n",
    "        temp=np.zeros(10)\n",
    "        if el==10:\n",
    "            temp[0]=1\n",
    "        elif el==1:\n",
    "            temp[1]=1\n",
    "        elif el==2:\n",
    "            temp[2]=1\n",
    "        elif el==3:\n",
    "            temp[3]=1\n",
    "        elif el==4:\n",
    "            temp[4]=1\n",
    "        elif el==5:\n",
    "            temp[5]=1\n",
    "        elif el==6:\n",
    "            temp[6]=1\n",
    "        elif el==7:\n",
    "            temp[7]=1\n",
    "        elif el==8:\n",
    "            temp[8]=1\n",
    "        elif el==9:\n",
    "            temp[9]=1\n",
    "        Ytr.append(temp)\n",
    "    return xtrain, np.asarray(Ytr)\n",
    "\n",
    "# train_data, train_labels = reformat(train_data, train_labels)\n",
    "# test_data, test_labels = reformat(test_data, test_labels)\n",
    "\n",
    "\n",
    "#============================================================================\n",
    "\n",
    "#==================BUILDING THE CNN==========================================\n",
    "\"\"\"\n",
    "Various Hyperparameters required for training the CNN.\n",
    "\"\"\"\n",
    "image_size = 28\n",
    "width = 28\n",
    "height = 28\n",
    "# channels = 3\n",
    "# for MNISt channels = 1\n",
    "channels = 1\n",
    "\n",
    "n_labels = 10\n",
    "patch = 5\n",
    "depth = 16\n",
    "hidden = 128\n",
    "dropout = 0.9375\n",
    "\n",
    "batch = 128\n",
    "learning_rate = 0.001\n",
    "\n",
    "\"\"\"\n",
    "Constructing the placeholders and variables in the TensorFlow Graph\n",
    "\"\"\"\n",
    "#Training Dataset\n",
    "tf_train_dataset = tf.placeholder(tf.float32, shape=(None, width, height, channels))\n",
    "#Training Labels\n",
    "tf_train_labels = tf.placeholder(tf.float32, shape=(None, n_labels))\n",
    "#Testing Dataset\n",
    "tf_test_dataset = tf.constant(test_data)\n",
    "\n",
    "#   Layer 1: (5, 5, 3, 16)\n",
    "layer1_weights = tf.Variable(tf.truncated_normal([patch, patch, channels, depth], stddev=0.1))\n",
    "layer1_biases = tf.Variable(tf.constant(1.0, shape=[depth]))\n",
    "\n",
    "#   Layer 2: (5, 5, 16, 16)\n",
    "layer2_weights = tf.Variable(tf.truncated_normal([patch, patch, depth, depth], stddev=0.1))\n",
    "layer2_biases = tf.Variable(tf.constant(1.0, shape=[depth]))\n",
    "\n",
    "#   Layer 3: (1024, 128)\n",
    "layer3_weights = tf.Variable(tf.truncated_normal([image_size // 4 * image_size // 4 * depth, hidden], stddev=0.1))\n",
    "layer3_biases = tf.Variable(tf.constant(1.0, shape=[hidden]))\n",
    "\n",
    "#   Layer 4: (128, 10)\n",
    "layer4_weights = tf.Variable(tf.truncated_normal([hidden, n_labels], stddev=0.1))\n",
    "layer4_biases = tf.Variable(tf.constant(1.0, shape=[n_labels]))\n",
    "\n",
    "dropout = tf.placeholder(tf.float32)\n",
    "\n",
    "def model(data):\n",
    "    #   Convolution 1 and RELU\n",
    "    conv1 = tf.nn.conv2d(data, layer1_weights, [1, 1, 1, 1], padding='SAME')\n",
    "    hidden1 = tf.nn.relu(conv1 + layer1_biases)\n",
    "    #   Max Pool\n",
    "    hidden2 = tf.nn.max_pool(hidden1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "    #   Convolution 2 and RELU\n",
    "    conv2 = tf.nn.conv2d(hidden2, layer2_weights, [1, 1, 1, 1], padding='SAME')\n",
    "    hidden3 = tf.nn.relu(conv2 + layer2_biases)\n",
    "    #   Max Pool\n",
    "    hidden4 = tf.nn.max_pool(hidden3, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "    shape = hidden4.get_shape().as_list()\n",
    "\n",
    "    reshape = tf.reshape(hidden4, [-1, shape[1] * shape[2] * shape[3]])\n",
    "    hidden5 = tf.nn.relu(tf.matmul(reshape, layer3_weights) + layer3_biases)\n",
    "    #   Dropout\n",
    "    dropout_layer = tf.nn.dropout(hidden5, 0.5)\n",
    "    \n",
    "    return tf.matmul(dropout_layer, layer4_weights) + layer4_biases\n",
    "\n",
    "logits = model(tf_train_dataset)\n",
    "# bug here \n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=tf_train_labels))\n",
    "optimizer = tf.train.AdamOptimizer(0.0001).minimize(loss)\n",
    "\n",
    "train_prediction = tf.nn.softmax(logits)\n",
    "test_prediction = tf.nn.softmax(model(tf_test_dataset))\n",
    "#============================================================================\n",
    "\n",
    "#==================TRAINING AND TESTING THE MODEL============================\n",
    "\"\"\"\n",
    "Accuracy function defined similar to the one taught in the Udacity Deep Learning Course\n",
    "Returns percentage of correct predictions by verifying with Labels\n",
    "\"\"\"\n",
    "def accuracy(predictions, labels):\n",
    "    return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "          / predictions.shape[0])\n",
    "\n",
    "#   Number of iterations\n",
    "num_steps = 10000\n",
    "\n",
    "with tf.Session() as session:\n",
    "    tf.initialize_all_variables().run()\n",
    "    print('Initialized')\n",
    "    average = 0\n",
    "    for step in range(num_steps):\n",
    "        #   Constucting the batch from the data set\n",
    "        offset = (step * batch) % (train_labels.shape[0] - batch)\n",
    "        batch_data = train_data[offset:(offset + batch), :, :, :]\n",
    "        batch_labels = train_labels[offset:(offset + batch), :]\n",
    "        #   Dictionary to be fed to TensorFlow Session\n",
    "        feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels, dropout: 0.93}\n",
    "        _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "        #   Calculating the Accuracy of the predictions\n",
    "        accu = accuracy(predictions, batch_labels)\n",
    "        if (step % 50 == 0):\n",
    "            print('Minibatch loss at step %d: %f' % (step, l))\n",
    "            print('Minibatch accuracy: %.1f%%' % accu)\n",
    "        average += accu\n",
    "    print(\"Average Accuracy : %f \" % (average / num_steps))\n",
    "    print(\"END OF TRAINING\")\n",
    "    \n",
    "    correct_prediction = tf.equal(tf.argmax(test_prediction, 1), tf.argmax(test_labels, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    acc = session.run(accuracy)\n",
    "    print(acc)\n",
    "    print(\"Average Accuracy : %d \" % acc)\n",
    "    print(\"END OF TESTING\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Attempted to use a closed Session.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-5f85dee5a1db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# type(accuracy.value)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/assistant/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/assistant/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    912\u001b[0m     \u001b[0;31m# Check session.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_closed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 914\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Attempted to use a closed Session.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    915\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       raise RuntimeError('The Session graph is empty.  Add operations to the '\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Attempted to use a closed Session."
     ]
    }
   ],
   "source": [
    "# type(accuracy.value)\n",
    "type(session.run(accuracy))\n",
    "accuracy.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "(55000, 784)\n",
      "(10000, 784)\n",
      "(55000, 10)\n",
      "after reshape: \n",
      "(55000, 28, 28, 1)\n",
      "(10000, 28, 28, 1)\n",
      "Train on 44000 samples, validate on 11000 samples\n",
      "Epoch 1/10\n",
      "44000/44000 [==============================] - 10s - loss: 0.1393 - acc: 0.9562 - val_loss: 0.0562 - val_acc: 0.9841\n",
      "Epoch 2/10\n",
      "44000/44000 [==============================] - 10s - loss: 0.0529 - acc: 0.9835 - val_loss: 0.0459 - val_acc: 0.9871\n",
      "Epoch 3/10\n",
      "44000/44000 [==============================] - 10s - loss: 0.0386 - acc: 0.9880 - val_loss: 0.0369 - val_acc: 0.9890\n",
      "Epoch 4/10\n",
      "44000/44000 [==============================] - 10s - loss: 0.0324 - acc: 0.9901 - val_loss: 0.0389 - val_acc: 0.9895\n",
      "Epoch 5/10\n",
      "44000/44000 [==============================] - 10s - loss: 0.0270 - acc: 0.9915 - val_loss: 0.0440 - val_acc: 0.9892\n",
      "Epoch 6/10\n",
      "44000/44000 [==============================] - 10s - loss: 0.0261 - acc: 0.9923 - val_loss: 0.0352 - val_acc: 0.9913\n",
      "Epoch 7/10\n",
      "44000/44000 [==============================] - 10s - loss: 0.0212 - acc: 0.9935 - val_loss: 0.0395 - val_acc: 0.9907\n",
      "Epoch 8/10\n",
      "44000/44000 [==============================] - 10s - loss: 0.0214 - acc: 0.9936 - val_loss: 0.0431 - val_acc: 0.9907\n",
      "Epoch 9/10\n",
      "44000/44000 [==============================] - 10s - loss: 0.0188 - acc: 0.9945 - val_loss: 0.0461 - val_acc: 0.9903\n",
      "Epoch 10/10\n",
      "44000/44000 [==============================] - 10s - loss: 0.0157 - acc: 0.9951 - val_loss: 0.0475 - val_acc: 0.9891\n",
      "CPU times: user 1min 56s, sys: 13.3 s, total: 2min 10s\n",
      "Wall time: 1min 48s\n",
      " 9888/10000 [============================>.] - ETA: 0s\n",
      "Test loss: 0.047\n",
      "Test accuracy: 0.990\n",
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# test accuracy 0.9915 with advnaced model\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "train_data = mnist.train.images\n",
    "train_labels = mnist.train.labels\n",
    "test_data = mnist.test.images\n",
    "test_labels = mnist.test.labels\n",
    "shape_train = train_data.shape\n",
    "shape_test = test_data.shape\n",
    "print(shape_train)\n",
    "print(shape_test)\n",
    "print(train_labels.shape)\n",
    "print(\"after reshape: \")\n",
    "train_data = train_data.reshape(len(train_data), 28, 28, 1)\n",
    "test_data = test_data.reshape(len(test_data), 28, 28, 1)\n",
    "shape_train = train_data.shape\n",
    "shape_test = test_data.shape\n",
    "print(shape_train)\n",
    "print(shape_test)\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D, GaussianNoise, MaxoutDense\n",
    "from keras.regularizers import l1, l2\n",
    "from keras.optimizers import SGD\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "\n",
    "# here are some settings for my network\n",
    "batch_size = 32\n",
    "nb_epoch = 10\n",
    "img_size = 28\n",
    "img_channels = 1\n",
    "nb_classes = 10\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(32, 5, 5, border_mode='same',\n",
    "                        input_shape=(img_size, img_size, img_channels)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(64, 5, 5))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Convolution2D(64, 3, 3, border_mode='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "# sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "%time his = model.fit(train_data, train_labels, \\\n",
    "          batch_size=batch_size, \\\n",
    "          nb_epoch=nb_epoch, \\\n",
    "          validation_split=0.2, \\\n",
    "          shuffle=True) \\\n",
    "\n",
    "# evaluate our model\n",
    "score = model.evaluate(test_data, test_labels, verbose=1)\n",
    "print('\\nTest loss: %.3f' % score[0])\n",
    "print('Test accuracy: %.3f' % score[1])\n",
    "\n",
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"mnist_model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"mnist_model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# keras on SVHN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 58605 samples, validate on 14652 samples\n",
      "Epoch 1/10\n",
      "58605/58605 [==============================] - 18s - loss: 0.8228 - acc: 0.7360 - val_loss: 0.4839 - val_acc: 0.8535\n",
      "Epoch 2/10\n",
      "58605/58605 [==============================] - 18s - loss: 0.4637 - acc: 0.8600 - val_loss: 0.3963 - val_acc: 0.8858\n",
      "Epoch 3/10\n",
      "58605/58605 [==============================] - 18s - loss: 0.3951 - acc: 0.8796 - val_loss: 0.3813 - val_acc: 0.8840\n",
      "Epoch 4/10\n",
      "58605/58605 [==============================] - 18s - loss: 0.3449 - acc: 0.8943 - val_loss: 0.3598 - val_acc: 0.8980\n",
      "Epoch 5/10\n",
      "58605/58605 [==============================] - 18s - loss: 0.3132 - acc: 0.9044 - val_loss: 0.3649 - val_acc: 0.8938\n",
      "Epoch 6/10\n",
      "58605/58605 [==============================] - 18s - loss: 0.2824 - acc: 0.9140 - val_loss: 0.3659 - val_acc: 0.8982\n",
      "Epoch 7/10\n",
      "58605/58605 [==============================] - 18s - loss: 0.2588 - acc: 0.9200 - val_loss: 0.3919 - val_acc: 0.8997\n",
      "Epoch 8/10\n",
      "58605/58605 [==============================] - 18s - loss: 0.2381 - acc: 0.9250 - val_loss: 0.3755 - val_acc: 0.8965\n",
      "Epoch 9/10\n",
      "58605/58605 [==============================] - 18s - loss: 0.2197 - acc: 0.9317 - val_loss: 0.3715 - val_acc: 0.8993\n",
      "Epoch 10/10\n",
      "58605/58605 [==============================] - 18s - loss: 0.2069 - acc: 0.9347 - val_loss: 0.4130 - val_acc: 0.8975\n",
      "CPU times: user 3min 8s, sys: 23.7 s, total: 3min 32s\n",
      "Wall time: 3min 5s\n",
      "26032/26032 [==============================] - 1s     \n",
      "\n",
      "Test loss: 0.477\n",
      "Test accuracy: 0.886\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D, GaussianNoise, MaxoutDense\n",
    "from keras.regularizers import l1, l2\n",
    "from keras.optimizers import SGD\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "train_data = scipy.io.loadmat('data/svhn_cropped/train_32x32.mat')['X']\n",
    "train_labels = scipy.io.loadmat('data/svhn_cropped/train_32x32.mat')['y']\n",
    "test_data = scipy.io.loadmat('data/svhn_cropped/test_32x32.mat')['X']\n",
    "test_labels = scipy.io.loadmat('data/svhn_cropped/test_32x32.mat')['y']\n",
    "\n",
    "shape_train = train_data.shape\n",
    "shape_test = test_data.shape\n",
    "\n",
    "# here are some settings for my network\n",
    "batch_size = 32\n",
    "nb_epoch = 10\n",
    "img_size = 32\n",
    "img_channels = 3\n",
    "nb_classes = 10\n",
    "\n",
    "train_data = train_data.astype('float32') / 128.0 - 1\n",
    "test_data = test_data.astype('float32') / 128.0 - 1\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Converting Labels to One Hot Encoding and Image Matrix to favourable dimensions\n",
    "\"\"\"\n",
    "def reformat(data, Y):\n",
    "    xtrain = []\n",
    "    trainLen = data.shape[3]\n",
    "    for x in range(trainLen):\n",
    "        xtrain.append(data[:,:,:,x])\n",
    "    xtrain = np.asarray(xtrain)\n",
    "    Ytr=[]\n",
    "    for el in Y:\n",
    "        temp=np.zeros(10)\n",
    "        if el==10:\n",
    "            temp[0]=1\n",
    "        elif el==1:\n",
    "            temp[1]=1\n",
    "        elif el==2:\n",
    "            temp[2]=1\n",
    "        elif el==3:\n",
    "            temp[3]=1\n",
    "        elif el==4:\n",
    "            temp[4]=1\n",
    "        elif el==5:\n",
    "            temp[5]=1\n",
    "        elif el==6:\n",
    "            temp[6]=1\n",
    "        elif el==7:\n",
    "            temp[7]=1\n",
    "        elif el==8:\n",
    "            temp[8]=1\n",
    "        elif el==9:\n",
    "            temp[9]=1\n",
    "        Ytr.append(temp)\n",
    "    return xtrain, np.asarray(Ytr)\n",
    "\n",
    "train_data, train_labels = reformat(train_data, train_labels)\n",
    "test_data, test_labels = reformat(test_data, test_labels)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(32, 5, 5, border_mode='same',\n",
    "                        input_shape=(img_size, img_size, img_channels)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(64, 5, 5))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Convolution2D(64, 3, 3, border_mode='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "# sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "%time his = model.fit(train_data, train_labels, \\\n",
    "          batch_size=batch_size, \\\n",
    "          nb_epoch=nb_epoch, \\\n",
    "          validation_split=0.2, \\\n",
    "          shuffle=True) \\\n",
    "\n",
    "# evaluate our model\n",
    "score = model.evaluate(test_data, test_labels, verbose=1)\n",
    "print('\\nTest loss: %.3f' % score[0])\n",
    "print('Test accuracy: %.3f' % score[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# keras pretrain on mnist, train on SVHN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking model input: expected convolution2d_input_8 to have shape (None, 28, 28, 1) but got array with shape (32, 32, 3, 73257)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-f6b5ba236d49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time his = model.fit(svhn_train_data, svhn_train_labels,           batch_size=batch_size,           nb_epoch=nb_epoch,           validation_split=0.2,           shuffle=True)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;31m# evaluate our model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msvhn_test_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msvhn_test_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/assistant/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mmagic\u001b[0;34m(self, arg_s)\u001b[0m\n\u001b[1;32m   2156\u001b[0m         \u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg_s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2157\u001b[0m         \u001b[0mmagic_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmagic_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefilter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mESC_MAGIC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2158\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2160\u001b[0m     \u001b[0;31m#-------------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/assistant/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line)\u001b[0m\n\u001b[1;32m   2077\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2078\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2079\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2080\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-59>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[0;32m/home/assistant/anaconda3/lib/python3.5/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/assistant/anaconda3/lib/python3.5/site-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1178\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/home/assistant/anaconda3/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m    662\u001b[0m                               \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m                               sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/home/assistant/anaconda3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch)\u001b[0m\n\u001b[1;32m   1066\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1067\u001b[0m             \u001b[0mcheck_batch_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1068\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1069\u001b[0m         \u001b[0;31m# prepare validation data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/assistant/anaconda3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_batch_dim, batch_size)\u001b[0m\n\u001b[1;32m    979\u001b[0m                                    \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minternal_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m                                    \u001b[0mcheck_batch_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m                                    exception_prefix='model input')\n\u001b[0m\u001b[1;32m    982\u001b[0m         y = standardize_input_data(y, self.output_names,\n\u001b[1;32m    983\u001b[0m                                    \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/assistant/anaconda3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_dim, exception_prefix)\u001b[0m\n\u001b[1;32m    111\u001b[0m                             \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                             \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                             str(array.shape))\n\u001b[0m\u001b[1;32m    114\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking model input: expected convolution2d_input_8 to have shape (None, 28, 28, 1) but got array with shape (32, 32, 3, 73257)"
     ]
    }
   ],
   "source": [
    "from keras.models import model_from_json\n",
    "svhn_train_data = scipy.io.loadmat('data/svhn_cropped/train_32x32.mat')['X']\n",
    "svhn_train_labels = scipy.io.loadmat('data/svhn_cropped/train_32x32.mat')['y']\n",
    "svhn_test_data = scipy.io.loadmat('data/svhn_cropped/test_32x32.mat')['X']\n",
    "svhn_test_labels = scipy.io.loadmat('data/svhn_cropped/test_32x32.mat')['y']\n",
    "\n",
    "shape_train = train_data.shape\n",
    "shape_test = test_data.shape\n",
    "\n",
    "with open('mnist_model.json', 'r') as json_file:\n",
    "    loaded_model_json = json_file.read()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"mnist_model.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "%time his = model.fit(svhn_train_data, svhn_train_labels, \\\n",
    "          batch_size=batch_size, \\\n",
    "          nb_epoch=nb_epoch, \\\n",
    "          validation_split=0.2, \\\n",
    "          shuffle=True) \\\n",
    "\n",
    "# evaluate our model\n",
    "score = model.evaluate(svhn_test_data, svhn_test_labels, verbose=1)\n",
    "print('\\nTest loss: %.3f' % score[0])\n",
    "print('Test accuracy: %.3f' % score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load json and create model\n",
    "json_file = open('models/small_mammals_model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "model_whole = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "model_whole.load_weights(\"models/small_mammals_model.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "%time his = model.fit(train_data, train_labels, \\\n",
    "          batch_size=batch_size, \\\n",
    "          nb_epoch=nb_epoch, \\\n",
    "          validation_split=0.2, \\\n",
    "          shuffle=True) \\\n",
    "\n",
    "# evaluate our model\n",
    "score = model.evaluate(test_data, test_labels, verbose=1)\n",
    "print('\\nTest loss: %.3f' % score[0])\n",
    "print('Test accuracy: %.3f' % score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# restore the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./mnist_model-10000\n",
      "WARNING:tensorflow:From <ipython-input-1-3cc90f6eaa49>:5: all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Please use tf.global_variables instead.\n",
      "[<tf.Variable 'Variable:0' shape=(5, 5, 3, 32) dtype=float32_ref>, <tf.Variable 'Variable_1:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'Variable_2:0' shape=(5, 5, 32, 64) dtype=float32_ref>, <tf.Variable 'Variable_3:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'Variable_4:0' shape=(4096, 1024) dtype=float32_ref>, <tf.Variable 'Variable_5:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'Variable_6:0' shape=(1024, 10) dtype=float32_ref>, <tf.Variable 'Variable_7:0' shape=(10,) dtype=float32_ref>, <tf.Variable 'beta1_power:0' shape=() dtype=float32_ref>, <tf.Variable 'beta2_power:0' shape=() dtype=float32_ref>, <tf.Variable 'Variable/Adam:0' shape=(5, 5, 3, 32) dtype=float32_ref>, <tf.Variable 'Variable/Adam_1:0' shape=(5, 5, 3, 32) dtype=float32_ref>, <tf.Variable 'Variable_1/Adam:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'Variable_1/Adam_1:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'Variable_2/Adam:0' shape=(5, 5, 32, 64) dtype=float32_ref>, <tf.Variable 'Variable_2/Adam_1:0' shape=(5, 5, 32, 64) dtype=float32_ref>, <tf.Variable 'Variable_3/Adam:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'Variable_3/Adam_1:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'Variable_4/Adam:0' shape=(4096, 1024) dtype=float32_ref>, <tf.Variable 'Variable_4/Adam_1:0' shape=(4096, 1024) dtype=float32_ref>, <tf.Variable 'Variable_5/Adam:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'Variable_5/Adam_1:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'Variable_6/Adam:0' shape=(1024, 10) dtype=float32_ref>, <tf.Variable 'Variable_6/Adam_1:0' shape=(1024, 10) dtype=float32_ref>, <tf.Variable 'Variable_7/Adam:0' shape=(10,) dtype=float32_ref>, <tf.Variable 'Variable_7/Adam_1:0' shape=(10,) dtype=float32_ref>, <tf.Variable 'Variable_8:0' shape=(5, 5, 3, 32) dtype=float32_ref>, <tf.Variable 'Variable_9:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'Variable_10:0' shape=(5, 5, 32, 64) dtype=float32_ref>, <tf.Variable 'Variable_11:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'Variable_12:0' shape=(4096, 1024) dtype=float32_ref>, <tf.Variable 'Variable_13:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'Variable_14:0' shape=(1024, 10) dtype=float32_ref>, <tf.Variable 'Variable_15:0' shape=(10,) dtype=float32_ref>, <tf.Variable 'beta1_power_1:0' shape=() dtype=float32_ref>, <tf.Variable 'beta2_power_1:0' shape=() dtype=float32_ref>, <tf.Variable 'Variable_8/Adam:0' shape=(5, 5, 3, 32) dtype=float32_ref>, <tf.Variable 'Variable_8/Adam_1:0' shape=(5, 5, 3, 32) dtype=float32_ref>, <tf.Variable 'Variable_9/Adam:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'Variable_9/Adam_1:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'Variable_10/Adam:0' shape=(5, 5, 32, 64) dtype=float32_ref>, <tf.Variable 'Variable_10/Adam_1:0' shape=(5, 5, 32, 64) dtype=float32_ref>, <tf.Variable 'Variable_11/Adam:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'Variable_11/Adam_1:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'Variable_12/Adam:0' shape=(4096, 1024) dtype=float32_ref>, <tf.Variable 'Variable_12/Adam_1:0' shape=(4096, 1024) dtype=float32_ref>, <tf.Variable 'Variable_13/Adam:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'Variable_13/Adam_1:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'Variable_14/Adam:0' shape=(1024, 10) dtype=float32_ref>, <tf.Variable 'Variable_14/Adam_1:0' shape=(1024, 10) dtype=float32_ref>, <tf.Variable 'Variable_15/Adam:0' shape=(10,) dtype=float32_ref>, <tf.Variable 'Variable_15/Adam_1:0' shape=(10,) dtype=float32_ref>, <tf.Variable 'Variable_16:0' shape=(5, 5, 3, 32) dtype=float32_ref>, <tf.Variable 'Variable_17:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'Variable_18:0' shape=(5, 5, 32, 64) dtype=float32_ref>, <tf.Variable 'Variable_19:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'Variable_20:0' shape=(4096, 1024) dtype=float32_ref>, <tf.Variable 'Variable_21:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'Variable_22:0' shape=(1024, 10) dtype=float32_ref>, <tf.Variable 'Variable_23:0' shape=(10,) dtype=float32_ref>, <tf.Variable 'beta1_power_2:0' shape=() dtype=float32_ref>, <tf.Variable 'beta2_power_2:0' shape=() dtype=float32_ref>, <tf.Variable 'Variable_16/Adam:0' shape=(5, 5, 3, 32) dtype=float32_ref>, <tf.Variable 'Variable_16/Adam_1:0' shape=(5, 5, 3, 32) dtype=float32_ref>, <tf.Variable 'Variable_17/Adam:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'Variable_17/Adam_1:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'Variable_18/Adam:0' shape=(5, 5, 32, 64) dtype=float32_ref>, <tf.Variable 'Variable_18/Adam_1:0' shape=(5, 5, 32, 64) dtype=float32_ref>, <tf.Variable 'Variable_19/Adam:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'Variable_19/Adam_1:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'Variable_20/Adam:0' shape=(4096, 1024) dtype=float32_ref>, <tf.Variable 'Variable_20/Adam_1:0' shape=(4096, 1024) dtype=float32_ref>, <tf.Variable 'Variable_21/Adam:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'Variable_21/Adam_1:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'Variable_22/Adam:0' shape=(1024, 10) dtype=float32_ref>, <tf.Variable 'Variable_22/Adam_1:0' shape=(1024, 10) dtype=float32_ref>, <tf.Variable 'Variable_23/Adam:0' shape=(10,) dtype=float32_ref>, <tf.Variable 'Variable_23/Adam_1:0' shape=(10,) dtype=float32_ref>, <tf.Variable 'Variable_24:0' shape=(5, 5, 3, 32) dtype=float32_ref>, <tf.Variable 'Variable_25:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'Variable_26:0' shape=(5, 5, 32, 64) dtype=float32_ref>, <tf.Variable 'Variable_27:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'Variable_28:0' shape=(4096, 1024) dtype=float32_ref>, <tf.Variable 'Variable_29:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'Variable_30:0' shape=(1024, 10) dtype=float32_ref>, <tf.Variable 'Variable_31:0' shape=(10,) dtype=float32_ref>, <tf.Variable 'beta1_power_3:0' shape=() dtype=float32_ref>, <tf.Variable 'beta2_power_3:0' shape=() dtype=float32_ref>, <tf.Variable 'Variable_24/Adam:0' shape=(5, 5, 3, 32) dtype=float32_ref>, <tf.Variable 'Variable_24/Adam_1:0' shape=(5, 5, 3, 32) dtype=float32_ref>, <tf.Variable 'Variable_25/Adam:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'Variable_25/Adam_1:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'Variable_26/Adam:0' shape=(5, 5, 32, 64) dtype=float32_ref>, <tf.Variable 'Variable_26/Adam_1:0' shape=(5, 5, 32, 64) dtype=float32_ref>, <tf.Variable 'Variable_27/Adam:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'Variable_27/Adam_1:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'Variable_28/Adam:0' shape=(4096, 1024) dtype=float32_ref>, <tf.Variable 'Variable_28/Adam_1:0' shape=(4096, 1024) dtype=float32_ref>, <tf.Variable 'Variable_29/Adam:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'Variable_29/Adam_1:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'Variable_30/Adam:0' shape=(1024, 10) dtype=float32_ref>, <tf.Variable 'Variable_30/Adam_1:0' shape=(1024, 10) dtype=float32_ref>, <tf.Variable 'Variable_31/Adam:0' shape=(10,) dtype=float32_ref>, <tf.Variable 'Variable_31/Adam_1:0' shape=(10,) dtype=float32_ref>, <tf.Variable 'Variable_32:0' shape=(5, 5, 1, 32) dtype=float32_ref>, <tf.Variable 'Variable_33:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'Variable_34:0' shape=(5, 5, 32, 64) dtype=float32_ref>, <tf.Variable 'Variable_35:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'Variable_36:0' shape=(3136, 1024) dtype=float32_ref>, <tf.Variable 'Variable_37:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'Variable_38:0' shape=(1024, 10) dtype=float32_ref>, <tf.Variable 'Variable_39:0' shape=(10,) dtype=float32_ref>, <tf.Variable 'beta1_power_4:0' shape=() dtype=float32_ref>, <tf.Variable 'beta2_power_4:0' shape=() dtype=float32_ref>, <tf.Variable 'Variable_32/Adam:0' shape=(5, 5, 1, 32) dtype=float32_ref>, <tf.Variable 'Variable_32/Adam_1:0' shape=(5, 5, 1, 32) dtype=float32_ref>, <tf.Variable 'Variable_33/Adam:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'Variable_33/Adam_1:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'Variable_34/Adam:0' shape=(5, 5, 32, 64) dtype=float32_ref>, <tf.Variable 'Variable_34/Adam_1:0' shape=(5, 5, 32, 64) dtype=float32_ref>, <tf.Variable 'Variable_35/Adam:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'Variable_35/Adam_1:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'Variable_36/Adam:0' shape=(3136, 1024) dtype=float32_ref>, <tf.Variable 'Variable_36/Adam_1:0' shape=(3136, 1024) dtype=float32_ref>, <tf.Variable 'Variable_37/Adam:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'Variable_37/Adam_1:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'Variable_38/Adam:0' shape=(1024, 10) dtype=float32_ref>, <tf.Variable 'Variable_38/Adam_1:0' shape=(1024, 10) dtype=float32_ref>, <tf.Variable 'Variable_39/Adam:0' shape=(10,) dtype=float32_ref>, <tf.Variable 'Variable_39/Adam_1:0' shape=(10,) dtype=float32_ref>, <tf.Variable 'Variable_40:0' shape=(5, 5, 1, 32) dtype=float32_ref>, <tf.Variable 'Variable_41:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'Variable_42:0' shape=(5, 5, 32, 64) dtype=float32_ref>, <tf.Variable 'Variable_43:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'Variable_44:0' shape=(3136, 1024) dtype=float32_ref>, <tf.Variable 'Variable_45:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'Variable_46:0' shape=(1024, 10) dtype=float32_ref>, <tf.Variable 'Variable_47:0' shape=(10,) dtype=float32_ref>, <tf.Variable 'beta1_power_5:0' shape=() dtype=float32_ref>, <tf.Variable 'beta2_power_5:0' shape=() dtype=float32_ref>, <tf.Variable 'Variable_40/Adam:0' shape=(5, 5, 1, 32) dtype=float32_ref>, <tf.Variable 'Variable_40/Adam_1:0' shape=(5, 5, 1, 32) dtype=float32_ref>, <tf.Variable 'Variable_41/Adam:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'Variable_41/Adam_1:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'Variable_42/Adam:0' shape=(5, 5, 32, 64) dtype=float32_ref>, <tf.Variable 'Variable_42/Adam_1:0' shape=(5, 5, 32, 64) dtype=float32_ref>, <tf.Variable 'Variable_43/Adam:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'Variable_43/Adam_1:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'Variable_44/Adam:0' shape=(3136, 1024) dtype=float32_ref>, <tf.Variable 'Variable_44/Adam_1:0' shape=(3136, 1024) dtype=float32_ref>, <tf.Variable 'Variable_45/Adam:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'Variable_45/Adam_1:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'Variable_46/Adam:0' shape=(1024, 10) dtype=float32_ref>, <tf.Variable 'Variable_46/Adam_1:0' shape=(1024, 10) dtype=float32_ref>, <tf.Variable 'Variable_47/Adam:0' shape=(10,) dtype=float32_ref>, <tf.Variable 'Variable_47/Adam_1:0' shape=(10,) dtype=float32_ref>, <tf.Variable 'Variable_48:0' shape=(5, 5, 1, 32) dtype=float32_ref>, <tf.Variable 'Variable_49:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'Variable_50:0' shape=(5, 5, 32, 64) dtype=float32_ref>, <tf.Variable 'Variable_51:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'Variable_52:0' shape=(3136, 1024) dtype=float32_ref>, <tf.Variable 'Variable_53:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'Variable_54:0' shape=(1024, 10) dtype=float32_ref>, <tf.Variable 'Variable_55:0' shape=(10,) dtype=float32_ref>, <tf.Variable 'beta1_power_6:0' shape=() dtype=float32_ref>, <tf.Variable 'beta2_power_6:0' shape=() dtype=float32_ref>, <tf.Variable 'Variable_48/Adam:0' shape=(5, 5, 1, 32) dtype=float32_ref>, <tf.Variable 'Variable_48/Adam_1:0' shape=(5, 5, 1, 32) dtype=float32_ref>, <tf.Variable 'Variable_49/Adam:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'Variable_49/Adam_1:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'Variable_50/Adam:0' shape=(5, 5, 32, 64) dtype=float32_ref>, <tf.Variable 'Variable_50/Adam_1:0' shape=(5, 5, 32, 64) dtype=float32_ref>, <tf.Variable 'Variable_51/Adam:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'Variable_51/Adam_1:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'Variable_52/Adam:0' shape=(3136, 1024) dtype=float32_ref>, <tf.Variable 'Variable_52/Adam_1:0' shape=(3136, 1024) dtype=float32_ref>, <tf.Variable 'Variable_53/Adam:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'Variable_53/Adam_1:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'Variable_54/Adam:0' shape=(1024, 10) dtype=float32_ref>, <tf.Variable 'Variable_54/Adam_1:0' shape=(1024, 10) dtype=float32_ref>, <tf.Variable 'Variable_55/Adam:0' shape=(10,) dtype=float32_ref>, <tf.Variable 'Variable_55/Adam_1:0' shape=(10,) dtype=float32_ref>, <tf.Variable 'Variable_56:0' shape=(5, 5, 3, 16) dtype=float32_ref>, <tf.Variable 'Variable_57:0' shape=(16,) dtype=float32_ref>, <tf.Variable 'Variable_58:0' shape=(5, 5, 16, 16) dtype=float32_ref>, <tf.Variable 'Variable_59:0' shape=(16,) dtype=float32_ref>, <tf.Variable 'Variable_60:0' shape=(1024, 128) dtype=float32_ref>, <tf.Variable 'Variable_61:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'Variable_62:0' shape=(128, 10) dtype=float32_ref>, <tf.Variable 'Variable_63:0' shape=(10,) dtype=float32_ref>, <tf.Variable 'beta1_power_7:0' shape=() dtype=float32_ref>, <tf.Variable 'beta2_power_7:0' shape=() dtype=float32_ref>, <tf.Variable 'Variable_56/Adam:0' shape=(5, 5, 3, 16) dtype=float32_ref>, <tf.Variable 'Variable_56/Adam_1:0' shape=(5, 5, 3, 16) dtype=float32_ref>, <tf.Variable 'Variable_57/Adam:0' shape=(16,) dtype=float32_ref>, <tf.Variable 'Variable_57/Adam_1:0' shape=(16,) dtype=float32_ref>, <tf.Variable 'Variable_58/Adam:0' shape=(5, 5, 16, 16) dtype=float32_ref>, <tf.Variable 'Variable_58/Adam_1:0' shape=(5, 5, 16, 16) dtype=float32_ref>, <tf.Variable 'Variable_59/Adam:0' shape=(16,) dtype=float32_ref>, <tf.Variable 'Variable_59/Adam_1:0' shape=(16,) dtype=float32_ref>, <tf.Variable 'Variable_60/Adam:0' shape=(1024, 128) dtype=float32_ref>, <tf.Variable 'Variable_60/Adam_1:0' shape=(1024, 128) dtype=float32_ref>, <tf.Variable 'Variable_61/Adam:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'Variable_61/Adam_1:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'Variable_62/Adam:0' shape=(128, 10) dtype=float32_ref>, <tf.Variable 'Variable_62/Adam_1:0' shape=(128, 10) dtype=float32_ref>, <tf.Variable 'Variable_63/Adam:0' shape=(10,) dtype=float32_ref>, <tf.Variable 'Variable_63/Adam_1:0' shape=(10,) dtype=float32_ref>, <tf.Variable 'Variable_64:0' shape=(5, 5, 1, 16) dtype=float32_ref>, <tf.Variable 'Variable_65:0' shape=(16,) dtype=float32_ref>, <tf.Variable 'Variable_66:0' shape=(5, 5, 16, 16) dtype=float32_ref>, <tf.Variable 'Variable_67:0' shape=(16,) dtype=float32_ref>, <tf.Variable 'Variable_68:0' shape=(784, 128) dtype=float32_ref>, <tf.Variable 'Variable_69:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'Variable_70:0' shape=(128, 10) dtype=float32_ref>, <tf.Variable 'Variable_71:0' shape=(10,) dtype=float32_ref>, <tf.Variable 'beta1_power_8:0' shape=() dtype=float32_ref>, <tf.Variable 'beta2_power_8:0' shape=() dtype=float32_ref>, <tf.Variable 'Variable_64/Adam:0' shape=(5, 5, 1, 16) dtype=float32_ref>, <tf.Variable 'Variable_64/Adam_1:0' shape=(5, 5, 1, 16) dtype=float32_ref>, <tf.Variable 'Variable_65/Adam:0' shape=(16,) dtype=float32_ref>, <tf.Variable 'Variable_65/Adam_1:0' shape=(16,) dtype=float32_ref>, <tf.Variable 'Variable_66/Adam:0' shape=(5, 5, 16, 16) dtype=float32_ref>, <tf.Variable 'Variable_66/Adam_1:0' shape=(5, 5, 16, 16) dtype=float32_ref>, <tf.Variable 'Variable_67/Adam:0' shape=(16,) dtype=float32_ref>, <tf.Variable 'Variable_67/Adam_1:0' shape=(16,) dtype=float32_ref>, <tf.Variable 'Variable_68/Adam:0' shape=(784, 128) dtype=float32_ref>, <tf.Variable 'Variable_68/Adam_1:0' shape=(784, 128) dtype=float32_ref>, <tf.Variable 'Variable_69/Adam:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'Variable_69/Adam_1:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'Variable_70/Adam:0' shape=(128, 10) dtype=float32_ref>, <tf.Variable 'Variable_70/Adam_1:0' shape=(128, 10) dtype=float32_ref>, <tf.Variable 'Variable_71/Adam:0' shape=(10,) dtype=float32_ref>, <tf.Variable 'Variable_71/Adam_1:0' shape=(10,) dtype=float32_ref>, <tf.Variable 'Variable_72:0' shape=(5, 5, 1, 32) dtype=float32_ref>, <tf.Variable 'Variable_73:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'Variable_74:0' shape=(5, 5, 32, 64) dtype=float32_ref>, <tf.Variable 'Variable_75:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'Variable_76:0' shape=(3136, 1024) dtype=float32_ref>, <tf.Variable 'Variable_77:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'Variable_78:0' shape=(1024, 10) dtype=float32_ref>, <tf.Variable 'Variable_79:0' shape=(10,) dtype=float32_ref>, <tf.Variable 'beta1_power_9:0' shape=() dtype=float32_ref>, <tf.Variable 'beta2_power_9:0' shape=() dtype=float32_ref>, <tf.Variable 'Variable_72/Adam:0' shape=(5, 5, 1, 32) dtype=float32_ref>, <tf.Variable 'Variable_72/Adam_1:0' shape=(5, 5, 1, 32) dtype=float32_ref>, <tf.Variable 'Variable_73/Adam:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'Variable_73/Adam_1:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'Variable_74/Adam:0' shape=(5, 5, 32, 64) dtype=float32_ref>, <tf.Variable 'Variable_74/Adam_1:0' shape=(5, 5, 32, 64) dtype=float32_ref>, <tf.Variable 'Variable_75/Adam:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'Variable_75/Adam_1:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'Variable_76/Adam:0' shape=(3136, 1024) dtype=float32_ref>, <tf.Variable 'Variable_76/Adam_1:0' shape=(3136, 1024) dtype=float32_ref>, <tf.Variable 'Variable_77/Adam:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'Variable_77/Adam_1:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'Variable_78/Adam:0' shape=(1024, 10) dtype=float32_ref>, <tf.Variable 'Variable_78/Adam_1:0' shape=(1024, 10) dtype=float32_ref>, <tf.Variable 'Variable_79/Adam:0' shape=(10,) dtype=float32_ref>, <tf.Variable 'Variable_79/Adam_1:0' shape=(10,) dtype=float32_ref>, <tf.Variable 'Variable_80:0' shape=(5, 5, 1, 32) dtype=float32_ref>, <tf.Variable 'Variable_81:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'Variable_82:0' shape=(5, 5, 32, 64) dtype=float32_ref>, <tf.Variable 'Variable_83:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'Variable_84:0' shape=(3136, 1024) dtype=float32_ref>, <tf.Variable 'Variable_85:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'Variable_86:0' shape=(1024, 10) dtype=float32_ref>, <tf.Variable 'Variable_87:0' shape=(10,) dtype=float32_ref>, <tf.Variable 'beta1_power_10:0' shape=() dtype=float32_ref>, <tf.Variable 'beta2_power_10:0' shape=() dtype=float32_ref>, <tf.Variable 'Variable_80/Adam:0' shape=(5, 5, 1, 32) dtype=float32_ref>, <tf.Variable 'Variable_80/Adam_1:0' shape=(5, 5, 1, 32) dtype=float32_ref>, <tf.Variable 'Variable_81/Adam:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'Variable_81/Adam_1:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'Variable_82/Adam:0' shape=(5, 5, 32, 64) dtype=float32_ref>, <tf.Variable 'Variable_82/Adam_1:0' shape=(5, 5, 32, 64) dtype=float32_ref>, <tf.Variable 'Variable_83/Adam:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'Variable_83/Adam_1:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'Variable_84/Adam:0' shape=(3136, 1024) dtype=float32_ref>, <tf.Variable 'Variable_84/Adam_1:0' shape=(3136, 1024) dtype=float32_ref>, <tf.Variable 'Variable_85/Adam:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'Variable_85/Adam_1:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'Variable_86/Adam:0' shape=(1024, 10) dtype=float32_ref>, <tf.Variable 'Variable_86/Adam_1:0' shape=(1024, 10) dtype=float32_ref>, <tf.Variable 'Variable_87/Adam:0' shape=(10,) dtype=float32_ref>, <tf.Variable 'Variable_87/Adam_1:0' shape=(10,) dtype=float32_ref>, <tf.Variable 'conv_1/W:0' shape=(5, 5, 1, 32) dtype=float32_ref>, <tf.Variable 'conv_1/B:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'conv_2/W:0' shape=(5, 5, 32, 64) dtype=float32_ref>, <tf.Variable 'conv_2/B:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'fc_1/W:0' shape=(3136, 1024) dtype=float32_ref>, <tf.Variable 'fc_1/B:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'fc_2/W:0' shape=(1024, 10) dtype=float32_ref>, <tf.Variable 'fc_2/B:0' shape=(10,) dtype=float32_ref>, <tf.Variable 'beta1_power_11:0' shape=() dtype=float32_ref>, <tf.Variable 'beta2_power_11:0' shape=() dtype=float32_ref>, <tf.Variable 'conv_1/W/Adam:0' shape=(5, 5, 1, 32) dtype=float32_ref>, <tf.Variable 'conv_1/W/Adam_1:0' shape=(5, 5, 1, 32) dtype=float32_ref>, <tf.Variable 'conv_1/B/Adam:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'conv_1/B/Adam_1:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'conv_2/W/Adam:0' shape=(5, 5, 32, 64) dtype=float32_ref>, <tf.Variable 'conv_2/W/Adam_1:0' shape=(5, 5, 32, 64) dtype=float32_ref>, <tf.Variable 'conv_2/B/Adam:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'conv_2/B/Adam_1:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'fc_1/W/Adam:0' shape=(3136, 1024) dtype=float32_ref>, <tf.Variable 'fc_1/W/Adam_1:0' shape=(3136, 1024) dtype=float32_ref>, <tf.Variable 'fc_1/B/Adam:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'fc_1/B/Adam_1:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'fc_2/W/Adam:0' shape=(1024, 10) dtype=float32_ref>, <tf.Variable 'fc_2/W/Adam_1:0' shape=(1024, 10) dtype=float32_ref>, <tf.Variable 'fc_2/B/Adam:0' shape=(10,) dtype=float32_ref>, <tf.Variable 'fc_2/B/Adam_1:0' shape=(10,) dtype=float32_ref>, <tf.Variable 'conv_1_1/W:0' shape=(5, 5, 1, 32) dtype=float32_ref>, <tf.Variable 'conv_1_1/B:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'conv_2_1/W:0' shape=(5, 5, 32, 64) dtype=float32_ref>, <tf.Variable 'conv_2_1/B:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'fc_1_1/W:0' shape=(3136, 1024) dtype=float32_ref>, <tf.Variable 'fc_1_1/B:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'fc_2_1/W:0' shape=(1024, 10) dtype=float32_ref>, <tf.Variable 'fc_2_1/B:0' shape=(10,) dtype=float32_ref>, <tf.Variable 'beta1_power_12:0' shape=() dtype=float32_ref>, <tf.Variable 'beta2_power_12:0' shape=() dtype=float32_ref>, <tf.Variable 'conv_1_1/W/Adam:0' shape=(5, 5, 1, 32) dtype=float32_ref>, <tf.Variable 'conv_1_1/W/Adam_1:0' shape=(5, 5, 1, 32) dtype=float32_ref>, <tf.Variable 'conv_1_1/B/Adam:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'conv_1_1/B/Adam_1:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'conv_2_1/W/Adam:0' shape=(5, 5, 32, 64) dtype=float32_ref>, <tf.Variable 'conv_2_1/W/Adam_1:0' shape=(5, 5, 32, 64) dtype=float32_ref>, <tf.Variable 'conv_2_1/B/Adam:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'conv_2_1/B/Adam_1:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'fc_1_1/W/Adam:0' shape=(3136, 1024) dtype=float32_ref>, <tf.Variable 'fc_1_1/W/Adam_1:0' shape=(3136, 1024) dtype=float32_ref>, <tf.Variable 'fc_1_1/B/Adam:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'fc_1_1/B/Adam_1:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'fc_2_1/W/Adam:0' shape=(1024, 10) dtype=float32_ref>, <tf.Variable 'fc_2_1/W/Adam_1:0' shape=(1024, 10) dtype=float32_ref>, <tf.Variable 'fc_2_1/B/Adam:0' shape=(10,) dtype=float32_ref>, <tf.Variable 'fc_2_1/B/Adam_1:0' shape=(10,) dtype=float32_ref>, <tf.Variable 'Variable_88:0' shape=(5, 5, 3, 32) dtype=float32_ref>, <tf.Variable 'Variable_89:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'Variable_90:0' shape=(5, 5, 32, 64) dtype=float32_ref>, <tf.Variable 'Variable_91:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'Variable_92:0' shape=(4096, 1024) dtype=float32_ref>, <tf.Variable 'Variable_93:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'Variable_94:0' shape=(1024, 10) dtype=float32_ref>, <tf.Variable 'Variable_95:0' shape=(10,) dtype=float32_ref>, <tf.Variable 'beta1_power_13:0' shape=() dtype=float32_ref>, <tf.Variable 'beta2_power_13:0' shape=() dtype=float32_ref>, <tf.Variable 'Variable_88/Adam:0' shape=(5, 5, 3, 32) dtype=float32_ref>, <tf.Variable 'Variable_88/Adam_1:0' shape=(5, 5, 3, 32) dtype=float32_ref>, <tf.Variable 'Variable_89/Adam:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'Variable_89/Adam_1:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'Variable_90/Adam:0' shape=(5, 5, 32, 64) dtype=float32_ref>, <tf.Variable 'Variable_90/Adam_1:0' shape=(5, 5, 32, 64) dtype=float32_ref>, <tf.Variable 'Variable_91/Adam:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'Variable_91/Adam_1:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'Variable_92/Adam:0' shape=(4096, 1024) dtype=float32_ref>, <tf.Variable 'Variable_92/Adam_1:0' shape=(4096, 1024) dtype=float32_ref>, <tf.Variable 'Variable_93/Adam:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'Variable_93/Adam_1:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'Variable_94/Adam:0' shape=(1024, 10) dtype=float32_ref>, <tf.Variable 'Variable_94/Adam_1:0' shape=(1024, 10) dtype=float32_ref>, <tf.Variable 'Variable_95/Adam:0' shape=(10,) dtype=float32_ref>, <tf.Variable 'Variable_95/Adam_1:0' shape=(10,) dtype=float32_ref>, <tf.Variable 'conv_1_2/W:0' shape=(5, 5, 3, 32) dtype=float32_ref>, <tf.Variable 'conv_1_2/B:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'conv_2_2/W:0' shape=(5, 5, 32, 64) dtype=float32_ref>, <tf.Variable 'conv_2_2/B:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'fc_1_2/W:0' shape=(4096, 1024) dtype=float32_ref>, <tf.Variable 'fc_1_2/B:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'fc_2_2/W:0' shape=(1024, 10) dtype=float32_ref>, <tf.Variable 'fc_2_2/B:0' shape=(10,) dtype=float32_ref>, <tf.Variable 'beta1_power_14:0' shape=() dtype=float32_ref>, <tf.Variable 'beta2_power_14:0' shape=() dtype=float32_ref>, <tf.Variable 'conv_1_2/W/Adam:0' shape=(5, 5, 3, 32) dtype=float32_ref>, <tf.Variable 'conv_1_2/W/Adam_1:0' shape=(5, 5, 3, 32) dtype=float32_ref>, <tf.Variable 'conv_1_2/B/Adam:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'conv_1_2/B/Adam_1:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'conv_2_2/W/Adam:0' shape=(5, 5, 32, 64) dtype=float32_ref>, <tf.Variable 'conv_2_2/W/Adam_1:0' shape=(5, 5, 32, 64) dtype=float32_ref>, <tf.Variable 'conv_2_2/B/Adam:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'conv_2_2/B/Adam_1:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'fc_1_2/W/Adam:0' shape=(4096, 1024) dtype=float32_ref>, <tf.Variable 'fc_1_2/W/Adam_1:0' shape=(4096, 1024) dtype=float32_ref>, <tf.Variable 'fc_1_2/B/Adam:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'fc_1_2/B/Adam_1:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'fc_2_2/W/Adam:0' shape=(1024, 10) dtype=float32_ref>, <tf.Variable 'fc_2_2/W/Adam_1:0' shape=(1024, 10) dtype=float32_ref>, <tf.Variable 'fc_2_2/B/Adam:0' shape=(10,) dtype=float32_ref>, <tf.Variable 'fc_2_2/B/Adam_1:0' shape=(10,) dtype=float32_ref>, <tf.Variable 'conv_1_3/W:0' shape=(5, 5, 3, 32) dtype=float32_ref>, <tf.Variable 'conv_1_3/B:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'conv_2_3/W:0' shape=(5, 5, 32, 64) dtype=float32_ref>, <tf.Variable 'conv_2_3/B:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'fc_1_3/W:0' shape=(4096, 1024) dtype=float32_ref>, <tf.Variable 'fc_1_3/B:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'fc_2_3/W:0' shape=(1024, 10) dtype=float32_ref>, <tf.Variable 'fc_2_3/B:0' shape=(10,) dtype=float32_ref>, <tf.Variable 'beta1_power_15:0' shape=() dtype=float32_ref>, <tf.Variable 'beta2_power_15:0' shape=() dtype=float32_ref>, <tf.Variable 'conv_1_3/W/Adam:0' shape=(5, 5, 3, 32) dtype=float32_ref>, <tf.Variable 'conv_1_3/W/Adam_1:0' shape=(5, 5, 3, 32) dtype=float32_ref>, <tf.Variable 'conv_1_3/B/Adam:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'conv_1_3/B/Adam_1:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'conv_2_3/W/Adam:0' shape=(5, 5, 32, 64) dtype=float32_ref>, <tf.Variable 'conv_2_3/W/Adam_1:0' shape=(5, 5, 32, 64) dtype=float32_ref>, <tf.Variable 'conv_2_3/B/Adam:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'conv_2_3/B/Adam_1:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'fc_1_3/W/Adam:0' shape=(4096, 1024) dtype=float32_ref>, <tf.Variable 'fc_1_3/W/Adam_1:0' shape=(4096, 1024) dtype=float32_ref>, <tf.Variable 'fc_1_3/B/Adam:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'fc_1_3/B/Adam_1:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'fc_2_3/W/Adam:0' shape=(1024, 10) dtype=float32_ref>, <tf.Variable 'fc_2_3/W/Adam_1:0' shape=(1024, 10) dtype=float32_ref>, <tf.Variable 'fc_2_3/B/Adam:0' shape=(10,) dtype=float32_ref>, <tf.Variable 'fc_2_3/B/Adam_1:0' shape=(10,) dtype=float32_ref>, <tf.Variable 'conv_1_4/W:0' shape=(5, 5, 1, 32) dtype=float32_ref>, <tf.Variable 'conv_1_4/B:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'conv_2_4/W:0' shape=(5, 5, 32, 64) dtype=float32_ref>, <tf.Variable 'conv_2_4/B:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'fc_1_4/W:0' shape=(3136, 1024) dtype=float32_ref>, <tf.Variable 'fc_1_4/B:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'fc_2_4/W:0' shape=(1024, 10) dtype=float32_ref>, <tf.Variable 'fc_2_4/B:0' shape=(10,) dtype=float32_ref>, <tf.Variable 'beta1_power_16:0' shape=() dtype=float32_ref>, <tf.Variable 'beta2_power_16:0' shape=() dtype=float32_ref>, <tf.Variable 'conv_1_4/W/Adam:0' shape=(5, 5, 1, 32) dtype=float32_ref>, <tf.Variable 'conv_1_4/W/Adam_1:0' shape=(5, 5, 1, 32) dtype=float32_ref>, <tf.Variable 'conv_1_4/B/Adam:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'conv_1_4/B/Adam_1:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'conv_2_4/W/Adam:0' shape=(5, 5, 32, 64) dtype=float32_ref>, <tf.Variable 'conv_2_4/W/Adam_1:0' shape=(5, 5, 32, 64) dtype=float32_ref>, <tf.Variable 'conv_2_4/B/Adam:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'conv_2_4/B/Adam_1:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'fc_1_4/W/Adam:0' shape=(3136, 1024) dtype=float32_ref>, <tf.Variable 'fc_1_4/W/Adam_1:0' shape=(3136, 1024) dtype=float32_ref>, <tf.Variable 'fc_1_4/B/Adam:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'fc_1_4/B/Adam_1:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'fc_2_4/W/Adam:0' shape=(1024, 10) dtype=float32_ref>, <tf.Variable 'fc_2_4/W/Adam_1:0' shape=(1024, 10) dtype=float32_ref>, <tf.Variable 'fc_2_4/B/Adam:0' shape=(10,) dtype=float32_ref>, <tf.Variable 'fc_2_4/B/Adam_1:0' shape=(10,) dtype=float32_ref>, <tf.Variable 'conv_1_5/W:0' shape=(5, 5, 1, 32) dtype=float32_ref>, <tf.Variable 'conv_1_5/B:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'conv_2_5/W:0' shape=(5, 5, 32, 64) dtype=float32_ref>, <tf.Variable 'conv_2_5/B:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'fc_1_5/W:0' shape=(3136, 1024) dtype=float32_ref>, <tf.Variable 'fc_1_5/B:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'fc_2_5/W:0' shape=(1024, 10) dtype=float32_ref>, <tf.Variable 'fc_2_5/B:0' shape=(10,) dtype=float32_ref>, <tf.Variable 'beta1_power_17:0' shape=() dtype=float32_ref>, <tf.Variable 'beta2_power_17:0' shape=() dtype=float32_ref>, <tf.Variable 'conv_1_5/W/Adam:0' shape=(5, 5, 1, 32) dtype=float32_ref>, <tf.Variable 'conv_1_5/W/Adam_1:0' shape=(5, 5, 1, 32) dtype=float32_ref>, <tf.Variable 'conv_1_5/B/Adam:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'conv_1_5/B/Adam_1:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'conv_2_5/W/Adam:0' shape=(5, 5, 32, 64) dtype=float32_ref>, <tf.Variable 'conv_2_5/W/Adam_1:0' shape=(5, 5, 32, 64) dtype=float32_ref>, <tf.Variable 'conv_2_5/B/Adam:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'conv_2_5/B/Adam_1:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'fc_1_5/W/Adam:0' shape=(3136, 1024) dtype=float32_ref>, <tf.Variable 'fc_1_5/W/Adam_1:0' shape=(3136, 1024) dtype=float32_ref>, <tf.Variable 'fc_1_5/B/Adam:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'fc_1_5/B/Adam_1:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'fc_2_5/W/Adam:0' shape=(1024, 10) dtype=float32_ref>, <tf.Variable 'fc_2_5/W/Adam_1:0' shape=(1024, 10) dtype=float32_ref>, <tf.Variable 'fc_2_5/B/Adam:0' shape=(10,) dtype=float32_ref>, <tf.Variable 'fc_2_5/B/Adam_1:0' shape=(10,) dtype=float32_ref>, <tf.Variable 'conv_1_6/W:0' shape=(5, 5, 3, 32) dtype=float32_ref>, <tf.Variable 'conv_1_6/B:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'conv_2_6/W:0' shape=(5, 5, 32, 64) dtype=float32_ref>, <tf.Variable 'conv_2_6/B:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'fc_1_6/W:0' shape=(4096, 1024) dtype=float32_ref>, <tf.Variable 'fc_1_6/B:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'fc_2_6/W:0' shape=(1024, 10) dtype=float32_ref>, <tf.Variable 'fc_2_6/B:0' shape=(10,) dtype=float32_ref>, <tf.Variable 'beta1_power_18:0' shape=() dtype=float32_ref>, <tf.Variable 'beta2_power_18:0' shape=() dtype=float32_ref>, <tf.Variable 'conv_1_6/W/Adam:0' shape=(5, 5, 3, 32) dtype=float32_ref>, <tf.Variable 'conv_1_6/W/Adam_1:0' shape=(5, 5, 3, 32) dtype=float32_ref>, <tf.Variable 'conv_1_6/B/Adam:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'conv_1_6/B/Adam_1:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'conv_2_6/W/Adam:0' shape=(5, 5, 32, 64) dtype=float32_ref>, <tf.Variable 'conv_2_6/W/Adam_1:0' shape=(5, 5, 32, 64) dtype=float32_ref>, <tf.Variable 'conv_2_6/B/Adam:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'conv_2_6/B/Adam_1:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'fc_1_6/W/Adam:0' shape=(4096, 1024) dtype=float32_ref>, <tf.Variable 'fc_1_6/W/Adam_1:0' shape=(4096, 1024) dtype=float32_ref>, <tf.Variable 'fc_1_6/B/Adam:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'fc_1_6/B/Adam_1:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'fc_2_6/W/Adam:0' shape=(1024, 10) dtype=float32_ref>, <tf.Variable 'fc_2_6/W/Adam_1:0' shape=(1024, 10) dtype=float32_ref>, <tf.Variable 'fc_2_6/B/Adam:0' shape=(10,) dtype=float32_ref>, <tf.Variable 'fc_2_6/B/Adam_1:0' shape=(10,) dtype=float32_ref>, <tf.Variable 'conv_1_7/W:0' shape=(5, 5, 3, 32) dtype=float32_ref>, <tf.Variable 'conv_1_7/B:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'conv_2_7/W:0' shape=(5, 5, 32, 64) dtype=float32_ref>, <tf.Variable 'conv_2_7/B:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'fc_1_7/W:0' shape=(4096, 1024) dtype=float32_ref>, <tf.Variable 'fc_1_7/B:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'fc_2_7/W:0' shape=(1024, 10) dtype=float32_ref>, <tf.Variable 'fc_2_7/B:0' shape=(10,) dtype=float32_ref>, <tf.Variable 'beta1_power_19:0' shape=() dtype=float32_ref>, <tf.Variable 'beta2_power_19:0' shape=() dtype=float32_ref>, <tf.Variable 'conv_1_7/W/Adam:0' shape=(5, 5, 3, 32) dtype=float32_ref>, <tf.Variable 'conv_1_7/W/Adam_1:0' shape=(5, 5, 3, 32) dtype=float32_ref>, <tf.Variable 'conv_1_7/B/Adam:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'conv_1_7/B/Adam_1:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'conv_2_7/W/Adam:0' shape=(5, 5, 32, 64) dtype=float32_ref>, <tf.Variable 'conv_2_7/W/Adam_1:0' shape=(5, 5, 32, 64) dtype=float32_ref>, <tf.Variable 'conv_2_7/B/Adam:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'conv_2_7/B/Adam_1:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'fc_1_7/W/Adam:0' shape=(4096, 1024) dtype=float32_ref>, <tf.Variable 'fc_1_7/W/Adam_1:0' shape=(4096, 1024) dtype=float32_ref>, <tf.Variable 'fc_1_7/B/Adam:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'fc_1_7/B/Adam_1:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'fc_2_7/W/Adam:0' shape=(1024, 10) dtype=float32_ref>, <tf.Variable 'fc_2_7/W/Adam_1:0' shape=(1024, 10) dtype=float32_ref>, <tf.Variable 'fc_2_7/B/Adam:0' shape=(10,) dtype=float32_ref>, <tf.Variable 'fc_2_7/B/Adam_1:0' shape=(10,) dtype=float32_ref>, <tf.Variable 'conv_1_8/W:0' shape=(5, 5, 1, 32) dtype=float32_ref>, <tf.Variable 'conv_1_8/B:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'conv_2_8/W:0' shape=(5, 5, 32, 64) dtype=float32_ref>, <tf.Variable 'conv_2_8/B:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'fc_1_8/W:0' shape=(3136, 1024) dtype=float32_ref>, <tf.Variable 'fc_1_8/B:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'fc_2_8/W:0' shape=(1024, 10) dtype=float32_ref>, <tf.Variable 'fc_2_8/B:0' shape=(10,) dtype=float32_ref>, <tf.Variable 'beta1_power_20:0' shape=() dtype=float32_ref>, <tf.Variable 'beta2_power_20:0' shape=() dtype=float32_ref>, <tf.Variable 'conv_1_8/W/Adam:0' shape=(5, 5, 1, 32) dtype=float32_ref>, <tf.Variable 'conv_1_8/W/Adam_1:0' shape=(5, 5, 1, 32) dtype=float32_ref>, <tf.Variable 'conv_1_8/B/Adam:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'conv_1_8/B/Adam_1:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'conv_2_8/W/Adam:0' shape=(5, 5, 32, 64) dtype=float32_ref>, <tf.Variable 'conv_2_8/W/Adam_1:0' shape=(5, 5, 32, 64) dtype=float32_ref>, <tf.Variable 'conv_2_8/B/Adam:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'conv_2_8/B/Adam_1:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'fc_1_8/W/Adam:0' shape=(3136, 1024) dtype=float32_ref>, <tf.Variable 'fc_1_8/W/Adam_1:0' shape=(3136, 1024) dtype=float32_ref>, <tf.Variable 'fc_1_8/B/Adam:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'fc_1_8/B/Adam_1:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'fc_2_8/W/Adam:0' shape=(1024, 10) dtype=float32_ref>, <tf.Variable 'fc_2_8/W/Adam_1:0' shape=(1024, 10) dtype=float32_ref>, <tf.Variable 'fc_2_8/B/Adam:0' shape=(10,) dtype=float32_ref>, <tf.Variable 'fc_2_8/B/Adam_1:0' shape=(10,) dtype=float32_ref>, <tf.Variable 'conv_1_9/W:0' shape=(5, 5, 1, 32) dtype=float32_ref>, <tf.Variable 'conv_1_9/B:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'conv_2_9/W:0' shape=(5, 5, 32, 64) dtype=float32_ref>, <tf.Variable 'conv_2_9/B:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'fc_1_9/W:0' shape=(3136, 1024) dtype=float32_ref>, <tf.Variable 'fc_1_9/B:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'fc_2_9/W:0' shape=(1024, 10) dtype=float32_ref>, <tf.Variable 'fc_2_9/B:0' shape=(10,) dtype=float32_ref>, <tf.Variable 'beta1_power_21:0' shape=() dtype=float32_ref>, <tf.Variable 'beta2_power_21:0' shape=() dtype=float32_ref>, <tf.Variable 'conv_1_9/W/Adam:0' shape=(5, 5, 1, 32) dtype=float32_ref>, <tf.Variable 'conv_1_9/W/Adam_1:0' shape=(5, 5, 1, 32) dtype=float32_ref>, <tf.Variable 'conv_1_9/B/Adam:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'conv_1_9/B/Adam_1:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'conv_2_9/W/Adam:0' shape=(5, 5, 32, 64) dtype=float32_ref>, <tf.Variable 'conv_2_9/W/Adam_1:0' shape=(5, 5, 32, 64) dtype=float32_ref>, <tf.Variable 'conv_2_9/B/Adam:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'conv_2_9/B/Adam_1:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'fc_1_9/W/Adam:0' shape=(3136, 1024) dtype=float32_ref>, <tf.Variable 'fc_1_9/W/Adam_1:0' shape=(3136, 1024) dtype=float32_ref>, <tf.Variable 'fc_1_9/B/Adam:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'fc_1_9/B/Adam_1:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'fc_2_9/W/Adam:0' shape=(1024, 10) dtype=float32_ref>, <tf.Variable 'fc_2_9/W/Adam_1:0' shape=(1024, 10) dtype=float32_ref>, <tf.Variable 'fc_2_9/B/Adam:0' shape=(10,) dtype=float32_ref>, <tf.Variable 'fc_2_9/B/Adam_1:0' shape=(10,) dtype=float32_ref>]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'W_conv1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-3cc90f6eaa49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# W_conv1 nto found\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW_conv1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'W_conv1' is not defined"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "with tf.Session() as sess:    \n",
    "    saver = tf.train.import_meta_graph('mnist_model-10000.meta')\n",
    "    saver.restore(sess,tf.train.latest_checkpoint('./'))\n",
    "    print(tf.all_variables())\n",
    "    # W_conv1 nto found\n",
    "    print(sess.run(W_conv1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.framework.ops.Tensor"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x_image[0, 0, 0, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# let's see if this model(architecture 2) can work well on SVHN, no pretraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test accuracy 0.9915 with advnaced model\n",
    "from __future__ import print_function\n",
    "import tensorflow as tf \n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "# from tensorflow.examples.tutorials.mnist import input_data\n",
    "# mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "#==================EXTRACTING AND ANALYSING DATA FROM .mat FILES===============\n",
    "\"\"\"\n",
    "X and Y Components of Training and Testing Data\n",
    "\"\"\"\n",
    "train_data = scipy.io.loadmat('data/svhn_cropped/train_32x32.mat')['X']\n",
    "train_labels = scipy.io.loadmat('data/svhn_cropped/train_32x32.mat')['y']\n",
    "test_data = scipy.io.loadmat('data/svhn_cropped/test_32x32.mat')['X']\n",
    "test_labels = scipy.io.loadmat('data/svhn_cropped/test_32x32.mat')['y']\n",
    "\n",
    "shape_train = train_data.shape\n",
    "shape_test = test_data.shape\n",
    "\"\"\"\n",
    "Plotting Class Labels against their respective frequencies in a Bar Graph\n",
    "\"\"\"\n",
    "temp_labels = train_labels.reshape(73257).tolist()\n",
    "temp_labels = dict(Counter(temp_labels))\n",
    "plt.bar(range(len(temp_labels)), temp_labels.values(), align='center', label='Training Labels')\n",
    "plt.xticks(range(len(temp_labels)), temp_labels.keys())\n",
    "temp_labels = test_labels.reshape(26032).tolist()\n",
    "temp_labels = dict(Counter(temp_labels))\n",
    "plt.bar(range(len(temp_labels)), temp_labels.values(), align='center', color='red', label='Testing Labels')\n",
    "plt.legend()\n",
    "plt.xlabel('Class Labels')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Frequency Distribution of Class Labels')\n",
    "plt.show()\n",
    "#============================================================================\n",
    "\n",
    "\n",
    "# print shape_train[3], \"Images with\", shape_train[0], \"x\", shape_train[0], \"RGB grid\"\n",
    "print(\"%d Images with %d x %d \" % (shape_train[3], shape_train[0], shape_train[0]))\n",
    "\n",
    "#==================NORMALISATION AND PREPROCESSING=============================================\n",
    "\n",
    "image_size = 32\n",
    "width = 32\n",
    "height = 32\n",
    "channels = 3\n",
    "\n",
    "n_labels = 10\n",
    "patch = 5\n",
    "depth = 16\n",
    "hidden = 128\n",
    "dropout = 0.9375\n",
    "\n",
    "batch = 16\n",
    "learning_rate = 0.001\n",
    "\n",
    "train_data = train_data.astype('float32') / 128.0 - 1\n",
    "test_data = test_data.astype('float32') / 128.0 - 1\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Converting Labels to One Hot Encoding and Image Matrix to favourable dimensions\n",
    "\"\"\"\n",
    "def reformat(data, Y):\n",
    "    xtrain = []\n",
    "    trainLen = data.shape[3]\n",
    "    for x in range(trainLen):\n",
    "        xtrain.append(data[:,:,:,x])\n",
    "    xtrain = np.asarray(xtrain)\n",
    "    Ytr=[]\n",
    "    for el in Y:\n",
    "        temp=np.zeros(10)\n",
    "        if el==10:\n",
    "            temp[0]=1\n",
    "        elif el==1:\n",
    "            temp[1]=1\n",
    "        elif el==2:\n",
    "            temp[2]=1\n",
    "        elif el==3:\n",
    "            temp[3]=1\n",
    "        elif el==4:\n",
    "            temp[4]=1\n",
    "        elif el==5:\n",
    "            temp[5]=1\n",
    "        elif el==6:\n",
    "            temp[6]=1\n",
    "        elif el==7:\n",
    "            temp[7]=1\n",
    "        elif el==8:\n",
    "            temp[8]=1\n",
    "        elif el==9:\n",
    "            temp[9]=1\n",
    "        Ytr.append(temp)\n",
    "    return xtrain, np.asarray(Ytr)\n",
    "\n",
    "train_data, train_labels = reformat(train_data, train_labels)\n",
    "test_data, test_labels = reformat(test_data, test_labels)\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME')\n",
    "# bug\n",
    "x  = tf.placeholder(tf.float32, [None, width, height, channels], name='x')\n",
    "y_ = tf.placeholder(tf.float32, [None, 10],  name='y_')\n",
    "# x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "\n",
    "# Convolutional layer 1\n",
    "W_conv1 = weight_variable([5, 5, 3, 32])\n",
    "b_conv1 = bias_variable([32])\n",
    "\n",
    "h_conv1 = tf.nn.relu(conv2d(x, W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "# Convolutional layer 2\n",
    "W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "print(h_pool2)\n",
    "# Fully connected layer 1\n",
    "# how do I get 7?\n",
    "# reshape has issues here\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 8*8*64])\n",
    "\n",
    "# replace 7*7*64 by 65536\n",
    "W_fc1 = weight_variable([8*8*64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "\n",
    "# Dropout\n",
    "keep_prob  = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "# Fully connected layer 2 (Output layer) or,  you can call it a readout layer\n",
    "W_fc2 = weight_variable([1024, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    "\n",
    "y = tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2, name='y')\n",
    "\n",
    "# Evaluation functions\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32), name='accuracy')\n",
    "\n",
    "# Training algorithm\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "\n",
    "# initialize a save the save the model\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Training steps\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "    for i in range(20000):\n",
    "        # Constucting the batch from the data set\n",
    "        offset = (i * batch) % (train_labels.shape[0] - batch)\n",
    "        batch_data = train_data[offset:(offset + batch), :, :, :]\n",
    "        batch_labels = train_labels[offset:(offset + batch), :]     \n",
    "        \n",
    "        # tracking training accuracy\n",
    "        if i%100 == 0:\n",
    "            train_accuracy = accuracy.eval(feed_dict={x: batch_data, y_: batch_labels, keep_prob: 1.0})\n",
    "            print(\"step %d, training accuracy %g\" % (i, train_accuracy))\n",
    "        train_step.run(feed_dict={x: batch_data, y_: batch_labels, keep_prob: 0.5})\n",
    "\n",
    "    print(\"test accuracy %g\" % accuracy.eval(feed_dict={x: test_data, y_: test_labels, keep_prob: 1.0}))\n",
    "    save_path = saver.save(sess, \"/tmp/model_shvn.ckpt\")\n",
    "    print(\"Model saved in file: %s\" % save_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# retrive prediction confidence by confidence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pretrain on MNIST, then train on SVHN\n",
    "# test pretrain effect error: different variable name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73257 Images with size 32 x 32 \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "At least two variables have the same name: Variable_15",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-745422bb0fea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;31m# initialize a save the save the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m \u001b[0msaver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSaver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;31m# Training steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/assistant/anaconda3/lib/python3.5/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, var_list, reshape, sharded, max_to_keep, keep_checkpoint_every_n_hours, name, restore_sequentially, saver_def, builder, defer_build, allow_empty, write_version, pad_step_number)\u001b[0m\n\u001b[1;32m   1054\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pad_step_number\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_step_number\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdefer_build\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaver_def\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_saver_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/assistant/anaconda3/lib/python3.5/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1084\u001b[0m           \u001b[0mkeep_checkpoint_every_n_hours\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keep_checkpoint_every_n_hours\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1085\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1086\u001b[0;31m           restore_sequentially=self._restore_sequentially)\n\u001b[0m\u001b[1;32m   1087\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaver_def\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1088\u001b[0m       \u001b[0;31m# Since self._name is used as a name_scope by builder(), we are\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/assistant/anaconda3/lib/python3.5/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, names_to_saveables, reshape, sharded, max_to_keep, keep_checkpoint_every_n_hours, name, restore_sequentially, filename)\u001b[0m\n\u001b[1;32m    671\u001b[0m         \u001b[0munique\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m     \"\"\"\n\u001b[0;32m--> 673\u001b[0;31m     \u001b[0msaveables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ValidateAndSliceInputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames_to_saveables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmax_to_keep\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m       \u001b[0mmax_to_keep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/assistant/anaconda3/lib/python3.5/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36m_ValidateAndSliceInputs\u001b[0;34m(self, names_to_saveables)\u001b[0m\n\u001b[1;32m    555\u001b[0m     \"\"\"\n\u001b[1;32m    556\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames_to_saveables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m       \u001b[0mnames_to_saveables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBaseSaverBuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpListToDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames_to_saveables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0msaveables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/assistant/anaconda3/lib/python3.5/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mOpListToDict\u001b[0;34m(op_list)\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnames_to_saveables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m           raise ValueError(\"At least two variables have the same name: %s\" %\n\u001b[0;32m--> 535\u001b[0;31m                            name)\n\u001b[0m\u001b[1;32m    536\u001b[0m         \u001b[0mnames_to_saveables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m       \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: At least two variables have the same name: Variable_15"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "\"\"\"\n",
    "X and Y Components of Training and Testing Data\n",
    "\"\"\"\n",
    "train_data = scipy.io.loadmat('data/svhn_cropped/train_32x32.mat')['X']\n",
    "train_labels = scipy.io.loadmat('data/svhn_cropped/train_32x32.mat')['y']\n",
    "test_data = scipy.io.loadmat('data/svhn_cropped/test_32x32.mat')['X']\n",
    "test_labels = scipy.io.loadmat('data/svhn_cropped/test_32x32.mat')['y']\n",
    "\n",
    "shape_train = train_data.shape\n",
    "shape_test = test_data.shape\n",
    "\"\"\"\n",
    "Plotting Class Labels against their respective frequencies in a Bar Graph\n",
    "\"\"\"\n",
    "# temp_labels = train_labels.reshape(73257).tolist()\n",
    "# temp_labels = dict(Counter(temp_labels))\n",
    "# plt.bar(range(len(temp_labels)), temp_labels.values(), align='center', label='Training Labels')\n",
    "# plt.xticks(range(len(temp_labels)), temp_labels.keys())\n",
    "# temp_labels = test_labels.reshape(26032).tolist()\n",
    "# temp_labels = dict(Counter(temp_labels))\n",
    "# plt.bar(range(len(temp_labels)), temp_labels.values(), align='center', color='red', label='Testing Labels')\n",
    "# plt.legend()\n",
    "# plt.xlabel('Class Labels')\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.title('Frequency Distribution of Class Labels')\n",
    "# plt.show()\n",
    "#============================================================================\n",
    "\n",
    "\n",
    "# print shape_train[3], \"Images with\", shape_train[0], \"x\", shape_train[0], \"RGB grid\"\n",
    "print(\"%d Images with size %d x %d \" % (shape_train[3], shape_train[0], shape_train[0]))\n",
    "\n",
    "#==================NORMALISATION AND PREPROCESSING=============================================\n",
    "\n",
    "image_size = 32\n",
    "width = 32\n",
    "height = 32\n",
    "channels = 3\n",
    "\n",
    "n_labels = 10\n",
    "patch = 5\n",
    "depth = 16\n",
    "hidden = 128\n",
    "dropout = 0.9375\n",
    "\n",
    "batch = 16\n",
    "learning_rate = 0.001\n",
    "\n",
    "train_data = train_data.astype('float32') / 128.0 - 1\n",
    "test_data = test_data.astype('float32') / 128.0 - 1\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Converting Labels to One Hot Encoding and Image Matrix to favourable dimensions\n",
    "\"\"\"\n",
    "def reformat(data, Y):\n",
    "    xtrain = []\n",
    "    trainLen = data.shape[3]\n",
    "    for x in range(trainLen):\n",
    "        xtrain.append(data[:,:,:,x])\n",
    "    xtrain = np.asarray(xtrain)\n",
    "    Ytr=[]\n",
    "    for el in Y:\n",
    "        temp=np.zeros(10)\n",
    "        if el==10:\n",
    "            temp[0]=1\n",
    "        elif el==1:\n",
    "            temp[1]=1\n",
    "        elif el==2:\n",
    "            temp[2]=1\n",
    "        elif el==3:\n",
    "            temp[3]=1\n",
    "        elif el==4:\n",
    "            temp[4]=1\n",
    "        elif el==5:\n",
    "            temp[5]=1\n",
    "        elif el==6:\n",
    "            temp[6]=1\n",
    "        elif el==7:\n",
    "            temp[7]=1\n",
    "        elif el==8:\n",
    "            temp[8]=1\n",
    "        elif el==9:\n",
    "            temp[9]=1\n",
    "        Ytr.append(temp)\n",
    "    return xtrain, np.asarray(Ytr)\n",
    "\n",
    "train_data, train_labels = reformat(train_data, train_labels)\n",
    "test_data, test_labels = reformat(test_data, test_labels)\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial, name='W')\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial, name='B')\n",
    "\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "x  = tf.placeholder(tf.float32, [None, width, height, channels], name='x')\n",
    "y_ = tf.placeholder(tf.float32, [None, 10],  name='y_')\n",
    "\n",
    "\n",
    "# Convolutional layer 1\n",
    "with tf.name_scope('conv_1'):\n",
    "    W_conv1 = weight_variable([5, 5, 3, 32])\n",
    "    b_conv1 = bias_variable([32])\n",
    "\n",
    "    h_conv1 = tf.nn.relu(conv2d(x, W_conv1) + b_conv1)\n",
    "    h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "# Convolutional layer 2\n",
    "with tf.name_scope('conv_2'):\n",
    "    W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "    b_conv2 = bias_variable([64])\n",
    "\n",
    "    h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "    h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "# Fully connected layer 1\n",
    "with tf.name_scope('fc_1'):\n",
    "    h_pool2_flat = tf.reshape(h_pool2, [-1, 8*8*64])\n",
    "\n",
    "    W_fc1 = weight_variable([8*8*64, 1024])\n",
    "    b_fc1 = bias_variable([1024])\n",
    "\n",
    "    h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "\n",
    "# Dropout\n",
    "keep_prob  = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "# Fully connected layer 2 (Output layer) or,  you can call it a readout layer\n",
    "with tf.name_scope('fc_2'):\n",
    "    W_fc2 = weight_variable([1024, 10])\n",
    "    b_fc2 = bias_variable([10])\n",
    "\n",
    "    y = tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2, name='y')\n",
    "\n",
    "# Evaluation functions\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32), name='accuracy')\n",
    "\n",
    "# Training algorithm\n",
    "# sine we are fintunning, we should try to use a smaller leanring rate\n",
    "# train_step = tf.train.AdamOptimizer(1e-5, name='Adam').minimize(cross_entropy)\n",
    "\n",
    "# initialize a save the save the model\n",
    "saver = tf.train.Saver()\n",
    "tf.all_variables()\n",
    "# Training steps\n",
    "with tf.Session() as sess:\n",
    "    # saver.restore(sess, \"/tmp/model_mnist.ckpt\")\n",
    "    # saver = tf.train.import_meta_graph('mnist_model-10000.meta')\n",
    "    saver.restore(sess,tf.train.latest_checkpoint('./'))\n",
    "    print(\"Model restored.\")\n",
    "    # sess.run(tf.initialize_all_variables())\n",
    "\n",
    "    # Restore variables from disk.\n",
    "\n",
    "    # Do some work with the model    \n",
    "    for i in range(20000):\n",
    "        # Constucting the batch from the data set\n",
    "        offset = (i * batch) % (train_labels.shape[0] - batch)\n",
    "        batch_data = train_data[offset:(offset + batch), :, :, :]\n",
    "        batch_labels = train_labels[offset:(offset + batch), :]     \n",
    "        \n",
    "        # tracking training accuracy\n",
    "        if i%100 == 0:\n",
    "            train_accuracy = accuracy.eval(feed_dict={x: batch_data, y_: batch_labels, keep_prob: 1.0})\n",
    "            print(\"step %d, training accuracy %g\" % (i, train_accuracy))\n",
    "        train_step.run(feed_dict={x: batch_data, y_: batch_labels, keep_prob: 0.5})\n",
    "\n",
    "    print(\"test accuracy %g\" % accuracy.eval(feed_dict={x: test_data, y_: test_labels, keep_prob: 1.0}))\n",
    "    save_path = saver.save(sess, \"pretrain_on_mnist_svhn_model\", global_step=20000)\n",
    "    print(\"Model saved in file: %s\" % save_path)\n",
    "#     max_steps = 20000\n",
    "#     for step in range(max_steps):\n",
    "#         batch_xs, batch_ys = mnist.train.next_batch(50)\n",
    "#         if (step % 100) == 0:\n",
    "#             print(step, sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels, keep_prob: 0.5}))\n",
    "#         sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys, keep_prob: 0.5})\n",
    "#     print(max_steps, sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model loading sample code(might be for the older version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add ops to save and restore all the variables.\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Later, launch the model, initialize the variables, do some work, save the\n",
    "# variables to disk.\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init_op)\n",
    "    # Do some work with the model.\n",
    "  \n",
    "    # Save the variables to disk.\n",
    "    save_path = saver.save(sess, \"/tmp/model.ckpt\")\n",
    "    print(\"Model saved in file: %s\" % save_path)\n",
    "\n",
    "# Restoring Variables\n",
    "\n",
    "# Add ops to save and restore all the variables.\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Later, launch the model, use the saver to restore variables from disk, and\n",
    "# do some work with the model.\n",
    "with tf.Session() as sess:\n",
    "    # Restore variables from disk.\n",
    "    saver.restore(sess, \"/tmp/model.ckpt\")\n",
    "    print(\"Model restored.\")\n",
    "    # Do some work with the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# no model reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73257 Images with 32 x 32 \n",
      "WARNING:tensorflow:From <ipython-input-2-47f2264ad0cf>:104: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "INFO:tensorflow:Restoring parameters from ./mnist_model-10000\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'h_fc1_drop' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-47f2264ad0cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0mx\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0my_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'y_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_fc1_drop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW_fc2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb_fc2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'y'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m     \u001b[0;31m# Evaluation functions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0mcross_entropy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction_indices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'h_fc1_drop' is not defined"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow as tf \n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "# from tensorflow.examples.tutorials.mnist import input_data\n",
    "# mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "#==================EXTRACTING AND ANALYSING DATA FROM .mat FILES===============\n",
    "\"\"\"\n",
    "X and Y Components of Training and Testing Data\n",
    "\"\"\"\n",
    "train_data = scipy.io.loadmat('data/svhn_cropped/train_32x32.mat')['X']\n",
    "train_labels = scipy.io.loadmat('data/svhn_cropped/train_32x32.mat')['y']\n",
    "test_data = scipy.io.loadmat('data/svhn_cropped/test_32x32.mat')['X']\n",
    "test_labels = scipy.io.loadmat('data/svhn_cropped/test_32x32.mat')['y']\n",
    "\n",
    "shape_train = train_data.shape\n",
    "shape_test = test_data.shape\n",
    "\n",
    "\"\"\"\n",
    "Plotting Class Labels against their respective frequencies in a Bar Graph\n",
    "\"\"\"\n",
    "# temp_labels = train_labels.reshape(73257).tolist()\n",
    "# temp_labels = dict(Counter(temp_labels))\n",
    "# plt.bar(range(len(temp_labels)), temp_labels.values(), align='center', label='Training Labels')\n",
    "# plt.xticks(range(len(temp_labels)), temp_labels.keys())\n",
    "# temp_labels = test_labels.reshape(26032).tolist()\n",
    "# temp_labels = dict(Counter(temp_labels))\n",
    "# plt.bar(range(len(temp_labels)), temp_labels.values(), align='center', color='red', label='Testing Labels')\n",
    "# plt.legend()\n",
    "# plt.xlabel('Class Labels')\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.title('Frequency Distribution of Class Labels')\n",
    "# plt.show()\n",
    "#============================================================================\n",
    "\n",
    "\n",
    "# print shape_train[3], \"Images with\", shape_train[0], \"x\", shape_train[0], \"RGB grid\"\n",
    "print(\"%d Images with %d x %d \" % (shape_train[3], shape_train[0], shape_train[0]))\n",
    "\n",
    "#==================NORMALISATION AND PREPROCESSING=============================================\n",
    "\n",
    "image_size = 32\n",
    "width = 32\n",
    "height = 32\n",
    "channels = 3\n",
    "\n",
    "n_labels = 10\n",
    "patch = 5\n",
    "depth = 16\n",
    "hidden = 128\n",
    "dropout = 0.9375\n",
    "\n",
    "batch = 16\n",
    "learning_rate = 0.001\n",
    "\n",
    "train_data = train_data.astype('float32') / 128.0 - 1\n",
    "test_data = test_data.astype('float32') / 128.0 - 1\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Converting Labels to One Hot Encoding and Image Matrix to favourable dimensions\n",
    "\"\"\"\n",
    "def reformat(data, Y):\n",
    "    xtrain = []\n",
    "    trainLen = data.shape[3]\n",
    "    for x in range(trainLen):\n",
    "        xtrain.append(data[:,:,:,x])\n",
    "    xtrain = np.asarray(xtrain)\n",
    "    Ytr=[]\n",
    "    for el in Y:\n",
    "        temp=np.zeros(10)\n",
    "        if el==10:\n",
    "            temp[0]=1\n",
    "        elif el==1:\n",
    "            temp[1]=1\n",
    "        elif el==2:\n",
    "            temp[2]=1\n",
    "        elif el==3:\n",
    "            temp[3]=1\n",
    "        elif el==4:\n",
    "            temp[4]=1\n",
    "        elif el==5:\n",
    "            temp[5]=1\n",
    "        elif el==6:\n",
    "            temp[6]=1\n",
    "        elif el==7:\n",
    "            temp[7]=1\n",
    "        elif el==8:\n",
    "            temp[8]=1\n",
    "        elif el==9:\n",
    "            temp[9]=1\n",
    "        Ytr.append(temp)\n",
    "    return xtrain, np.asarray(Ytr)\n",
    "\n",
    "train_data, train_labels = reformat(train_data, train_labels)\n",
    "test_data, test_labels = reformat(test_data, test_labels)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # saver.restore(sess, \"/tmp/model_mnist.ckpt\")\n",
    "    saver = tf.train.import_meta_graph('mnist_model-10000.meta')\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "    saver.restore(sess,tf.train.latest_checkpoint('./'))\n",
    "    x  = tf.placeholder(tf.float32, [None, width, height, channels], name='x')\n",
    "    y_ = tf.placeholder(tf.float32, [None, 10],  name='y_')\n",
    "    y = tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2, name='y')\n",
    "    # Evaluation functions\n",
    "    cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))\n",
    "    correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32), name='accuracy')\n",
    "\n",
    "    # Training algorithm\n",
    "    # sine we are fintunning, we should try to use a smaller leanring rate\n",
    "    train_step = tf.train.AdamOptimizer(1e-5, name='Adam').minimize(cross_entropy)\n",
    "    \n",
    "    print(\"Model restored.\")\n",
    "    # sess.run(tf.initialize_all_variables())\n",
    "\n",
    "    # Restore variables from disk.\n",
    "\n",
    "    # Do some work with the model    \n",
    "    for i in range(20000):\n",
    "        # Constucting the batch from the data set\n",
    "        offset = (i * batch) % (train_labels.shape[0] - batch)\n",
    "        batch_data = train_data[offset:(offset + batch), :, :, :]\n",
    "        batch_labels = train_labels[offset:(offset + batch), :]     \n",
    "        \n",
    "        # tracking training accuracy\n",
    "        if i%100 == 0:\n",
    "            train_accuracy = accuracy.eval(feed_dict={x: batch_data, y_: batch_labels, keep_prob: 1.0})\n",
    "            print(\"step %d, training accuracy %g\" % (i, train_accuracy))\n",
    "        train_step.run(feed_dict={x: batch_data, y_: batch_labels, keep_prob: 0.5})\n",
    "\n",
    "    print(\"test accuracy %g\" % accuracy.eval(feed_dict={x: test_data, y_: test_labels, keep_prob: 1.0}))\n",
    "    save_path = saver.save(sess, \"pretrain_on_mnist_svhn_model\", global_step=20000)\n",
    "    print(\"Model saved in file: %s\" % save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# helper founction of visulization of Tensorboard on ipython notebook(figuring out why is it not showing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# source: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/tutorials/deepdream/deepdream.ipynb\n",
    "from IPython.display import clear_output, Image, display, HTML\n",
    "\n",
    "def strip_consts(graph_def, max_const_size=32):\n",
    "    \"\"\"Strip large constant values from graph_def.\"\"\"\n",
    "    strip_def = tf.GraphDef()\n",
    "    for n0 in graph_def.node:\n",
    "        n = strip_def.node.add() \n",
    "        n.MergeFrom(n0)\n",
    "        if n.op == 'Const':\n",
    "            tensor = n.attr['value'].tensor\n",
    "            size = len(tensor.tensor_content)\n",
    "            if size > max_const_size:\n",
    "                tensor.tensor_content = bytes(\"<stripped %d bytes>\"%size, 'utf-8')\n",
    "    return strip_def\n",
    "\n",
    "def show_graph(graph_def, max_const_size=32):\n",
    "    \"\"\"Visualize TensorFlow graph.\"\"\"\n",
    "    if hasattr(graph_def, 'as_graph_def'):\n",
    "        graph_def = graph_def.as_graph_def()\n",
    "    strip_def = strip_consts(graph_def, max_const_size=max_const_size)\n",
    "    code = \"\"\"\n",
    "        <script>\n",
    "          function load() {{\n",
    "            document.getElementById(\"{id}\").pbtxt = {data};\n",
    "          }}\n",
    "        </script>\n",
    "        <link rel=\"import\" href=\"https://tensorboard.appspot.com/tf-graph-basic.build.html\" onload=load()>\n",
    "        <div style=\"height:600px\">\n",
    "          <tf-graph-basic id=\"{id}\"></tf-graph-basic>\n",
    "        </div>\n",
    "    \"\"\".format(data=repr(str(strip_def)), id='graph'+str(np.random.rand()))\n",
    "\n",
    "    iframe = \"\"\"\n",
    "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"{}\"></iframe>\n",
    "    \"\"\".format(code.replace('\"', '&quot;'))\n",
    "    display(HTML(iframe))\n",
    "    \n",
    "# def variable_summaries(var):\n",
    "#   \"\"\"Attach a lot of summaries to a Tensor (for TensorBoard visualization).\"\"\"\n",
    "#   with tf.name_scope('summaries'):\n",
    "#     mean = tf.reduce_mean(var)\n",
    "#     tf.summary.scalar('mean', mean)\n",
    "#     with tf.name_scope('stddev'):\n",
    "#       stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))\n",
    "#     tf.summary.scalar('stddev', stddev)\n",
    "#     tf.summary.scalar('max', tf.reduce_max(var))\n",
    "#     tf.summary.scalar('min', tf.reduce_min(var))\n",
    "#     tf.summary.histogram('histogram', var)\n",
    "\n",
    "    \n",
    "# show_graph(tf.get_default_graph().as_graph_def())\n",
    "\n",
    "# If your graph is saved as pbtxt, you could do\n",
    "\n",
    "# gdef = tf.GraphDef()\n",
    "# from google.protobuf import text_format\n",
    "# text_format.Merge(open(\"tf_persistent.pbtxt\").read(), gdef)\n",
    "# show_graph(gdef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/tensorflow/mnist/input_data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/tensorflow/mnist/input_data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/tensorflow/mnist/input_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/tensorflow/mnist/input_data/t10k-labels-idx1-ubyte.gz\n",
      "Accuracy at step 0: 0.0854\n"
     ]
    }
   ],
   "source": [
    "# Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the 'License');\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an 'AS IS' BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "\"\"\"A simple MNIST classifier which displays summaries in TensorBoard.\n",
    "\n",
    " This is an unimpressive MNIST model, but it is a good example of using\n",
    "tf.name_scope to make a graph legible in the TensorBoard graph explorer, and of\n",
    "naming summary tags so that they are grouped meaningfully in TensorBoard.\n",
    "\n",
    "It demonstrates the functionality of every TensorBoard dashboard.\n",
    "\"\"\"\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import sys\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "FLAGS = None\n",
    "\n",
    "\n",
    "def train():\n",
    "  # Import data\n",
    "  mnist = input_data.read_data_sets(FLAGS.data_dir,\n",
    "                                    one_hot=True,\n",
    "                                    fake_data=FLAGS.fake_data)\n",
    "\n",
    "  sess = tf.InteractiveSession()\n",
    "  # Create a multilayer model.\n",
    "\n",
    "  # Input placeholders\n",
    "  with tf.name_scope('input'):\n",
    "    x = tf.placeholder(tf.float32, [None, 784], name='x-input')\n",
    "    y_ = tf.placeholder(tf.float32, [None, 10], name='y-input')\n",
    "\n",
    "  with tf.name_scope('input_reshape'):\n",
    "    image_shaped_input = tf.reshape(x, [-1, 28, 28, 1])\n",
    "    tf.summary.image('input', image_shaped_input, 10)\n",
    "\n",
    "  # We can't initialize these variables to 0 - the network will get stuck.\n",
    "  def weight_variable(shape):\n",
    "    \"\"\"Create a weight variable with appropriate initialization.\"\"\"\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "  def bias_variable(shape):\n",
    "    \"\"\"Create a bias variable with appropriate initialization.\"\"\"\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "  def variable_summaries(var):\n",
    "    \"\"\"Attach a lot of summaries to a Tensor (for TensorBoard visualization).\"\"\"\n",
    "    with tf.name_scope('summaries'):\n",
    "      mean = tf.reduce_mean(var)\n",
    "      tf.summary.scalar('mean', mean)\n",
    "      with tf.name_scope('stddev'):\n",
    "        stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))\n",
    "      tf.summary.scalar('stddev', stddev)\n",
    "      tf.summary.scalar('max', tf.reduce_max(var))\n",
    "      tf.summary.scalar('min', tf.reduce_min(var))\n",
    "      tf.summary.histogram('histogram', var)\n",
    "\n",
    "  def nn_layer(input_tensor, input_dim, output_dim, layer_name, act=tf.nn.relu):\n",
    "    \"\"\"Reusable code for making a simple neural net layer.\n",
    "\n",
    "    It does a matrix multiply, bias add, and then uses relu to nonlinearize.\n",
    "    It also sets up name scoping so that the resultant graph is easy to read,\n",
    "    and adds a number of summary ops.\n",
    "    \"\"\"\n",
    "    # Adding a name scope ensures logical grouping of the layers in the graph.\n",
    "    with tf.name_scope(layer_name):\n",
    "      # This Variable will hold the state of the weights for the layer\n",
    "      with tf.name_scope('weights'):\n",
    "        weights = weight_variable([input_dim, output_dim])\n",
    "        variable_summaries(weights)\n",
    "      with tf.name_scope('biases'):\n",
    "        biases = bias_variable([output_dim])\n",
    "        variable_summaries(biases)\n",
    "      with tf.name_scope('Wx_plus_b'):\n",
    "        preactivate = tf.matmul(input_tensor, weights) + biases\n",
    "        tf.summary.histogram('pre_activations', preactivate)\n",
    "      activations = act(preactivate, name='activation')\n",
    "      tf.summary.histogram('activations', activations)\n",
    "      return activations\n",
    "\n",
    "  hidden1 = nn_layer(x, 784, 500, 'layer1')\n",
    "\n",
    "  with tf.name_scope('dropout'):\n",
    "    keep_prob = tf.placeholder(tf.float32)\n",
    "    tf.summary.scalar('dropout_keep_probability', keep_prob)\n",
    "    dropped = tf.nn.dropout(hidden1, keep_prob)\n",
    "\n",
    "  # Do not apply softmax activation yet, see below.\n",
    "  y = nn_layer(dropped, 500, 10, 'layer2', act=tf.identity)\n",
    "\n",
    "  with tf.name_scope('cross_entropy'):\n",
    "    # The raw formulation of cross-entropy,\n",
    "    #\n",
    "    # tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(tf.softmax(y)),\n",
    "    #                               reduction_indices=[1]))\n",
    "    #\n",
    "    # can be numerically unstable.\n",
    "    #\n",
    "    # So here we use tf.nn.softmax_cross_entropy_with_logits on the\n",
    "    # raw outputs of the nn_layer above, and then average across\n",
    "    # the batch.\n",
    "    diff = tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y)\n",
    "    with tf.name_scope('total'):\n",
    "      cross_entropy = tf.reduce_mean(diff)\n",
    "  tf.summary.scalar('cross_entropy', cross_entropy)\n",
    "\n",
    "  with tf.name_scope('train'):\n",
    "    train_step = tf.train.AdamOptimizer(FLAGS.learning_rate).minimize(\n",
    "        cross_entropy)\n",
    "\n",
    "  with tf.name_scope('accuracy'):\n",
    "    with tf.name_scope('correct_prediction'):\n",
    "      correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "    with tf.name_scope('accuracy'):\n",
    "      accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "  tf.summary.scalar('accuracy', accuracy)\n",
    "\n",
    "  # Merge all the summaries and write them out to /tmp/tensorflow/mnist/logs/mnist_with_summaries (by default)\n",
    "  merged = tf.summary.merge_all()\n",
    "  train_writer = tf.summary.FileWriter(FLAGS.log_dir + '/train', sess.graph)\n",
    "  test_writer = tf.summary.FileWriter(FLAGS.log_dir + '/test')\n",
    "  tf.global_variables_initializer().run()\n",
    "\n",
    "  # Train the model, and also write summaries.\n",
    "  # Every 10th step, measure test-set accuracy, and write test summaries\n",
    "  # All other steps, run train_step on training data, & add training summaries\n",
    "\n",
    "  def feed_dict(train):\n",
    "    \"\"\"Make a TensorFlow feed_dict: maps data onto Tensor placeholders.\"\"\"\n",
    "    if train or FLAGS.fake_data:\n",
    "      xs, ys = mnist.train.next_batch(100, fake_data=FLAGS.fake_data)\n",
    "      k = FLAGS.dropout\n",
    "    else:\n",
    "      xs, ys = mnist.test.images, mnist.test.labels\n",
    "      k = 1.0\n",
    "    return {x: xs, y_: ys, keep_prob: k}\n",
    "\n",
    "  for i in range(FLAGS.max_steps):\n",
    "    if i % 100 == 0:  # Record summaries and test-set accuracy\n",
    "      summary, acc = sess.run([merged, accuracy], feed_dict=feed_dict(False))\n",
    "      test_writer.add_summary(summary, i)\n",
    "      print('Accuracy at step %s: %s' % (i, acc))\n",
    "    else:  # Record train set summaries, and train\n",
    "      if i % 100 == 99:  # Record execution stats\n",
    "        run_options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)\n",
    "        run_metadata = tf.RunMetadata()\n",
    "        summary, _ = sess.run([merged, train_step],\n",
    "                              feed_dict=feed_dict(True),\n",
    "                              options=run_options,\n",
    "                              run_metadata=run_metadata)\n",
    "        train_writer.add_run_metadata(run_metadata, 'step%03d' % i)\n",
    "        train_writer.add_summary(summary, i)\n",
    "        print('Adding run metadata for', i)\n",
    "      else:  # Record a summary\n",
    "        summary, _ = sess.run([merged, train_step], feed_dict=feed_dict(True))\n",
    "        train_writer.add_summary(summary, i)\n",
    "  train_writer.close()\n",
    "  test_writer.close()\n",
    "\n",
    "\n",
    "def main(_):\n",
    "  if tf.gfile.Exists(FLAGS.log_dir):\n",
    "    tf.gfile.DeleteRecursively(FLAGS.log_dir)\n",
    "  tf.gfile.MakeDirs(FLAGS.log_dir)\n",
    "  train()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  parser = argparse.ArgumentParser()\n",
    "  parser.add_argument('--fake_data', nargs='?', const=True, type=bool,\n",
    "                      default=False,\n",
    "                      help='If true, uses fake data for unit testing.')\n",
    "  parser.add_argument('--max_steps', type=int, default=100,\n",
    "                      help='Number of steps to run trainer.')\n",
    "  parser.add_argument('--learning_rate', type=float, default=0.001,\n",
    "                      help='Initial learning rate')\n",
    "  parser.add_argument('--dropout', type=float, default=0.9,\n",
    "                      help='Keep probability for training dropout.')\n",
    "  parser.add_argument('--data_dir', type=str, default='/tmp/tensorflow/mnist/input_data',\n",
    "                      help='Directory for storing input data')\n",
    "  parser.add_argument('--log_dir', type=str, default='/tmp/tensorflow/mnist/logs/mnist_with_summaries',\n",
    "                      help='Summaries log directory')\n",
    "  FLAGS, unparsed = parser.parse_known_args()\n",
    "  tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
